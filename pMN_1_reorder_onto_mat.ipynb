{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import utils\n",
    "import connectome_create\n",
    "# viz_method = one of ['itkwidgets', 'vtk']\n",
    "viz_method = 'vtk'\n",
    "\n",
    "# import some of our favorite packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import warnings\n",
    "\n",
    "%matplotlib inline\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "# import nglui.statebuilder as ngstbld\n",
    "\n",
    "# # this is the EM specific package for querying the EM data\n",
    "from caveclient import CAVEclient\n",
    "\n",
    "\n",
    "# from meshparty import trimesh_io, trimesh_vtk\n",
    "# from meshparty import skeletonize, skeleton_io, skeleton\n",
    "import cloudvolume\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pathlib import Path\n",
    "# import json\n",
    "\n",
    "# with open(Path.home() / '.cloudvolume/secrets/'/'cave-secret.json') as f:\n",
    "#         tokens = json.load(f)\n",
    "        \n",
    "# seg_source = 'graphene://https://cave.fanc-fly.com/segmentation/table/mar2021_prod'\n",
    "# cv = cloudvolume.CloudVolume(cloudpath=seg_source, use_https=True, secrets=tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datastack_name = 'fanc_production_mar2021'\n",
    "\n",
    "client = CAVEclient(datastack_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# client = CAVEclient()\n",
    "\n",
    "# # if not os.path.isfile(os.path.expanduser(\"~/.cloudvolume/secrets/cave-secret.json\")):\n",
    "# client.auth.get_new_token(open=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you have not yet setup this computer, uncomment this below line\n",
    "# paste the token from the website in, and run the line\n",
    "\n",
    "# client.auth.save_token(token=\"c14cd7a3e18a1a697716a399afbf5778\", overwrite=True)\n",
    "\n",
    "# then comment or delete the line as you don't need to run it on this computer  again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load Premotor table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pre_to_df = connectome_create.load_pre_to_df(ext='with_class_no_frag')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_to_mn_df = connectome_create.load_pre_to_mn_df(ext='matched_typed_with_nt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create an index for pre_to_df with all the levels: cell_class\n",
    "cell_class, preferred_pool, NT, classification_system, cell_type, segID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppmn_idx = pre_to_df.index.to_frame()\n",
    "ppmn_idx['preferred_pool'] = 'empty'\n",
    "ppmn_idx['NT'] = 'empty'\n",
    "ppmn_idx['classification_system'] = 'empty'\n",
    "ppmn_idx['cell_type'] = 'empty'\n",
    "ppmn_idx = ppmn_idx[['cell_class', 'preferred_pool', 'NT', 'classification_system', 'cell_type', 'post_pt_root_id']]\n",
    "pre_to_df.index = pd.MultiIndex.from_frame(ppmn_idx)\n",
    "pre_to_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reorder the no frags df to have known pmns in the same order along both axes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "All = slice(None)\n",
    "\n",
    "def reorder_cell_class(pre_to_df,cclss):\n",
    "    clss_cols = pre_to_df.loc[All,(cclss,All,All,All,All,All,All)].columns.to_frame()\n",
    "    clss_cols = clss_cols.droplevel(['cell_class','preferred_pool', 'NT', 'classification_system', 'cell_type',])\n",
    "    clss_cols.index.rename('root_id',inplace=True)\n",
    "\n",
    "    clss = pre_to_df.loc[(cclss,All,All,All,All,All)]\n",
    "    clss_idx  = clss.index.to_frame()\n",
    "    clss.index = clss.index.droplevel(['cell_class','preferred_pool', 'NT', 'classification_system', 'cell_type',])\n",
    "    clss_idx.index = clss_idx.index.droplevel(['cell_class','preferred_pool', 'NT', 'classification_system', 'cell_type',])\n",
    "\n",
    "    # clss_cols has the order already figured out in previous code\n",
    "    # now reduce to the premotor neurons that are still around\n",
    "    print(clss_cols.shape)\n",
    "    clss_cols = clss_cols[clss_cols.segID.isin(clss.index.get_level_values('post_pt_root_id'))]\n",
    "    print(clss_cols.shape)\n",
    "\n",
    "    clss = clss.loc[clss_cols.segID]\n",
    "\n",
    "    clss_idx = clss_idx.loc[clss_cols.segID]\n",
    "    clss_idx = clss_idx.merge(clss_cols,left_index=True,right_on='segID',how='left')\n",
    "\n",
    "    clss_idx = clss_idx[['cell_class_y','preferred_pool_y', 'NT_y', 'classification_system_y', 'cell_type_y','post_pt_root_id']]\n",
    "    clss_idx = clss_idx.rename({\n",
    "            'cell_class_y': 'cell_class',\n",
    "            'preferred_pool_y': 'preferred_pool',\n",
    "            'NT_y': 'NT',\n",
    "            'classification_system_y': 'classification_system',\n",
    "            'cell_type_y': 'cell_type',\n",
    "            'post_pt_root_id': 'post_pt_root_id',\n",
    "        },axis=1)\n",
    "\n",
    "    # Index has cell_class, ..., post_pt_root_id\n",
    "    clss.index = pd.MultiIndex.from_frame(clss_idx)\n",
    "\n",
    "    print('pre_drop:     {}'.format(pre_to_df.shape))\n",
    "    pre_to_df = pre_to_df.drop(cclss,axis=0,level='cell_class')\n",
    "    print('post_drop:    {}'.format(pre_to_df.shape))\n",
    "    pre_to_df = pd.concat([clss,pre_to_df])\n",
    "    print('post_concat:  {}'.format(pre_to_df.shape))\n",
    "\n",
    "    print('input order:  {}...'.format(clss_cols.segID.values[0:5]))\n",
    "    print('output order: {}...'.format(clss.index.get_level_values('post_pt_root_id').values[0:5]))\n",
    "\n",
    "    print('output clss order: {}'.format(pre_to_df.index.get_level_values('cell_class').unique()))\n",
    "\n",
    "    return pre_to_df,clss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put the local neurons at the top, pushing the rest down\n",
    "pre_to_df, local = reorder_cell_class(pre_to_df=pre_to_df,cclss='local')\n",
    "\n",
    "# Put the intersegmental neurons at the top, pushing the rest down\n",
    "pre_to_df, intersegmental = reorder_cell_class(pre_to_df=pre_to_df,cclss='intersegmental')\n",
    "\n",
    "# Put the ascending neurons at the top, pushing the rest down\n",
    "pre_to_df, ascending = reorder_cell_class(pre_to_df=pre_to_df,cclss='ascending')\n",
    "\n",
    "# Put the sensory neurons at the top, pushing the rest down\n",
    "pre_to_df, sensory = reorder_cell_class(pre_to_df=pre_to_df,cclss='sensory')\n",
    "\n",
    "# Put the descending neurons at the top, pushing the rest down\n",
    "pre_to_df, descending = reorder_cell_class(pre_to_df=pre_to_df,cclss='descending')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorder_and_pool_motor_neurons(pre_to_df):\n",
    "    # This one adds the preferred pool to the motor neurons and appends to the pre_to_df at the top\n",
    "\n",
    "    cclss = 'motor'\n",
    "    clss_cols = pre_to_mn_df.columns.to_frame()\n",
    "    clss_cols['preferred_pool'] = 'empty'\n",
    "\n",
    "    muscle_tuple_dict = utils.get_motor_pool_tuple_dict()\n",
    "    pool_keys = [\n",
    "        'thorax_swing',\n",
    "        'thorax_stance',\n",
    "        'trochanter_extension',\n",
    "        'trochanter_flexion',\n",
    "        'femur_reductor',\n",
    "        'tibia_extensor',\n",
    "        'main_tibia_flexor',\n",
    "        # 'auxiliary_tibia_flexor_A',\n",
    "        'auxiliary_tibia_flexor_B',\n",
    "        'auxiliary_tibia_flexor_E',\n",
    "        'ltm',\n",
    "        'tarsus_depressor_med_venU',\n",
    "        'tarsus_depressor_noid',\n",
    "        ]\n",
    "\n",
    "    for key in pool_keys:\n",
    "        mn_tup = muscle_tuple_dict[key]\n",
    "        clss_cols.loc[mn_tup,'preferred_pool'] = key\n",
    "\n",
    "\n",
    "    clss_cols = clss_cols.set_index('segID',drop=False)\n",
    "    clss_cols.index.rename('root_id',inplace=True)\n",
    "    clss = pre_to_df.loc[(cclss,All,All,All,All,All)]\n",
    "    clss_idx  = clss.index.to_frame()\n",
    "    clss.index = clss.index.droplevel(['cell_class','preferred_pool', 'NT', 'classification_system', 'cell_type',])\n",
    "    clss_idx.index = clss_idx.index.droplevel(['cell_class','preferred_pool', 'NT', 'classification_system', 'cell_type',])\n",
    "\n",
    "    # clss_cols has the order already figured out in previous code\n",
    "    # now reduce to the premotor neurons that are still around\n",
    "    print(clss_cols.shape)\n",
    "    clss_cols = clss_cols[clss_cols.segID.isin(clss.index.get_level_values('post_pt_root_id'))]\n",
    "    print(clss_cols.shape)\n",
    "\n",
    "    clss = clss.loc[clss_cols.segID]\n",
    "\n",
    "    # reorder the index as well\n",
    "    clss_idx = clss_idx.loc[clss_cols.segID]\n",
    "    clss_idx = clss_idx.merge(clss_cols,left_index=True,right_on='segID',how='left')\n",
    "    clss_idx\n",
    "\n",
    "\n",
    "\n",
    "    clss_idx = clss_idx[['cell_class','preferred_pool_y', 'NT', 'muscle', 'rank','post_pt_root_id']]\n",
    "    clss_idx = clss_idx.rename({\n",
    "            'cell_class': 'cell_class',\n",
    "            'preferred_pool_y': 'preferred_pool',\n",
    "            'NT': 'NT',\n",
    "            'muscle': 'classification_system',\n",
    "            'rank': 'cell_type',\n",
    "            'post_pt_root_id': 'post_pt_root_id',\n",
    "        },axis=1)\n",
    "    clss_idx['NT'] = 'Glu'\n",
    "\n",
    "\n",
    "    # Index has cell_class, ..., post_pt_root_id\n",
    "    clss.index = pd.MultiIndex.from_frame(clss_idx)\n",
    "\n",
    "    print('pre_drop:     {}'.format(pre_to_df.shape))\n",
    "    pre_to_df = pre_to_df.drop(cclss,axis=0,level='cell_class')\n",
    "    print('post_drop:    {}'.format(pre_to_df.shape))\n",
    "    pre_to_df = pd.concat([clss,pre_to_df])\n",
    "    print('post_concat:  {}'.format(pre_to_df.shape))\n",
    "\n",
    "    print('input order:  {}...'.format(clss_cols.segID.values[0:5]))\n",
    "    print('output order: {}...'.format(clss.index.get_level_values('post_pt_root_id').values[0:5]))\n",
    "\n",
    "    print('output clss order: {}'.format(pre_to_df.index.get_level_values('cell_class').unique()))\n",
    "\n",
    "    return pre_to_df,clss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put the descending neurons at the top, pushing the rest down\n",
    "pre_to_df, motor = reorder_and_pool_motor_neurons(pre_to_df=pre_to_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review that pre_to_df makes sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pre_to_df.shape)\n",
    "print('input: {}'.format(pre_to_df.columns.names))\n",
    "print('output: {}'.format(pre_to_df.index.names))\n",
    "print(pre_to_df.columns.get_level_values('cell_class').unique())\n",
    "print(pre_to_df.index.get_level_values('cell_class').unique())\n",
    "\n",
    "pre_to_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the matrix\n",
    "connectome_create.save_pre_to_df(pre_to_df,ext='ordered_no_frags')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First, ensure that looking at the motor neurons gives the same connectome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tup = (All,All,All,All,All,All)\n",
    "output_tup = ('motor',All,All,All,All,All)\n",
    "\n",
    "pre_df_slice = pre_to_df.loc[output_tup,input_tup]\n",
    "\n",
    "%config InlineBackend.figure_formats = ['png']\n",
    "%matplotlib inline\n",
    "\n",
    "cmap = utils.white_dense()\n",
    "\n",
    "fig = plt.figure(1, figsize = [8,16])\n",
    "ax = sns.heatmap(np.log10(pre_df_slice.T.to_numpy()+1), cmap=cmap)\n",
    "cbar = ax.collections[0].colorbar\n",
    "# here set the labelsize by 20\n",
    "# cbar.ax.tick_params(labelsize=20)\n",
    "cbar.set_label(label = 'log 10 # of synapses', size=24)\n",
    "plt.xlabel('Motor Neurons', fontsize =18)\n",
    "plt.ylabel('All to motor', fontsize =18)\n",
    "plt.yticks(fontsize = 16)\n",
    "plt.xticks(fontsize = 16)\n",
    "plt.show()\n",
    "\n",
    "# Not enough here. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.0 ('fanc_analysis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "701379af8fa9566edb753273e8a4cc72928f1706e0a9299fef0231c034742a95"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
