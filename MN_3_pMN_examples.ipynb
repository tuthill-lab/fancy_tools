{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import utils\n",
    "import connectome_create\n",
    "# viz_method = one of ['itkwidgets', 'vtk']\n",
    "viz_method = 'vtk'\n",
    "\n",
    "# import some of our favorite packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import warnings\n",
    "\n",
    "%matplotlib inline\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import nglui.statebuilder as ngstbld\n",
    "# from nglui.statebuilder import *\n",
    "\n",
    "# # this is the EM specific package for querying the EM data\n",
    "from caveclient import CAVEclient\n",
    "\n",
    "\n",
    "# from meshparty import trimesh_io, trimesh_vtk\n",
    "# from meshparty import skeletonize, skeleton_io, skeleton\n",
    "# import cloudvolume\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pathlib import Path\n",
    "# import json\n",
    "\n",
    "# with open(Path.home() / '.cloudvolume/secrets/'/'cave-secret.json') as f:\n",
    "#         tokens = json.load(f)\n",
    "        \n",
    "# seg_source = 'graphene://https://cave.fanc-fly.com/segmentation/table/mar2021_prod'\n",
    "# cv = cloudvolume.CloudVolume(cloudpath=seg_source, use_https=True, secrets=tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datastack_name = 'fanc_production_mar2021'\n",
    "\n",
    "client = CAVEclient(datastack_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# client = CAVEclient()\n",
    "\n",
    "# # if not os.path.isfile(os.path.expanduser(\"~/.cloudvolume/secrets/cave-secret.json\")):\n",
    "# client.auth.get_new_token(open=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you have not yet setup this computer, uncomment this below line\n",
    "# paste the token from the website in, and run the line\n",
    "\n",
    "# client.auth.save_token(token=\"c14cd7a3e18a1a697716a399afbf5778\", overwrite=True)\n",
    "\n",
    "# then comment or delete the line as you don't need to run it on this computer  again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load Motor neuron table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pre_to_mn_df = connectome_create.load_old_pre_to_mn_df(ext='matched_typed_with_nt')\n",
    "# pre_to_mn_df = connectome_create.load_pre_to_mn_df(ext='edited')\n",
    "pre_to_mn_df.shape\n",
    "\n",
    "mpool_dict = utils.get_motor_pool_tuple_dict()\n",
    "pool_keys = [\n",
    "    'thorax_swing',\n",
    "    'thorax_stance',\n",
    "    'trochanter_extension',\n",
    "    'trochanter_flexion',\n",
    "    'femur_reductor',\n",
    "    'tibia_extensor',\n",
    "    'main_tibia_flexor',      # main_tibia_flexor for both main and A groups, or main_tibia_flexor_muscle for the muscle\n",
    "    'auxiliary_tibia_flexor_A',\n",
    "    'auxiliary_tibia_flexor_B',\n",
    "    'auxiliary_tibia_flexor_E',\n",
    "    'ltm',\n",
    "    'tarsus_depressor_med_venU',\n",
    "    'tarsus_depressor_noid',\n",
    "    ]\n",
    "pre_to_mn_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_formats = ['png']\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Put pools on the motor neuron table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "All = slice(None)\n",
    "\n",
    "def reorder_and_pool_motor_neurons():\n",
    "    # This one adds the preferred pool to the motor neurons and appends to the pre_to_df at the top\n",
    "\n",
    "    cclss = 'motor'\n",
    "    clss_cols = pre_to_mn_df.columns.to_frame()\n",
    "    clss_cols['preferred_pool'] = 'empty'\n",
    "\n",
    "    muscle_tuple_dict = utils.get_motor_pool_tuple_dict()\n",
    "    pool_keys = [\n",
    "        'thorax_swing',\n",
    "        'thorax_stance',\n",
    "        'trochanter_extension',\n",
    "        'trochanter_flexion',\n",
    "        'femur_reductor',\n",
    "        'tibia_extensor',\n",
    "        'main_tibia_flexor',\n",
    "        # 'auxiliary_tibia_flexor_A',\n",
    "        'auxiliary_tibia_flexor_B',\n",
    "        'auxiliary_tibia_flexor_E',\n",
    "        'ltm',\n",
    "        'tarsus_depressor_med_venU',\n",
    "        'tarsus_depressor_noid',\n",
    "        ]\n",
    "\n",
    "    for key in pool_keys:\n",
    "        mn_tup = muscle_tuple_dict[key]\n",
    "        clss_cols.loc[mn_tup,'preferred_pool'] = key\n",
    "\n",
    "\n",
    "    clss_cols = clss_cols.set_index('segID',drop=False)\n",
    "    clss_cols['cell_class'] = 'motor'\n",
    "    clss_cols.index.rename('root_id',inplace=True)\n",
    "    # clss = pre_to_df.loc[(cclss,All,All,All,All,All)]\n",
    "    # clss_idx  = clss.index.to_frame()\n",
    "    # clss.index = clss.index.droplevel(['cell_class','preferred_pool', 'NT', 'classification_system', 'cell_type',])\n",
    "    # clss_idx.index = clss_idx.index.droplevel(['cell_class','preferred_pool', 'NT', 'classification_system', 'cell_type',])\n",
    "\n",
    "    # clss_cols has the order already figured out in previous code\n",
    "    # now reduce to the premotor neurons that are still around\n",
    "    # print(clss_cols.shape)\n",
    "    # # clss_cols = clss_cols[clss_cols.segID.isin(clss.index.get_level_values('post_pt_root_id'))]\n",
    "    # print(clss_cols.shape)\n",
    "\n",
    "    # clss = clss.loc[clss_cols.segID]\n",
    "\n",
    "    # # reorder the index as well\n",
    "    # clss_idx = clss_idx.loc[clss_cols.segID]\n",
    "    # clss_idx = clss_idx.merge(clss_cols,left_index=True,right_on='segID',how='left')\n",
    "    # clss_idx\n",
    "\n",
    "    clss_cols = clss_cols[['cell_class','preferred_pool', 'muscle', 'rank','segID']]\n",
    "    clss_cols = clss_cols.rename({\n",
    "            'cell_class': 'cell_class',\n",
    "            'muscle': 'classification_system',\n",
    "            'rank': 'cell_type',\n",
    "            'segID': 'segID',\n",
    "        },axis=1)\n",
    "    clss_cols['NT'] = 'Glu'\n",
    "\n",
    "\n",
    "    # Index has cell_class, ..., post_pt_root_id\n",
    "    # clss.index = pd.MultiIndex.from_frame(clss_idx)\n",
    "\n",
    "    # print('pre_drop:     {}'.format(pre_to_df.shape))\n",
    "    # pre_to_df = pre_to_df.drop(cclss,axis=0,level='cell_class')\n",
    "    # print('post_drop:    {}'.format(pre_to_df.shape))\n",
    "    # pre_to_df = pd.concat([clss,pre_to_df])\n",
    "    # print('post_concat:  {}'.format(pre_to_df.shape))\n",
    "\n",
    "    # print('input order:  {}...'.format(clss_cols.segID.values[0:5]))\n",
    "    # print('output order: {}...'.format(clss.index.get_level_values('post_pt_root_id').values[0:5]))\n",
    "\n",
    "    # print('output clss order: {}'.format(pre_to_df.index.get_level_values('cell_class').unique()))\n",
    "\n",
    "    return clss_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clss_cols = reorder_and_pool_motor_neurons()\n",
    "pre_to_mn_df.columns = pd.MultiIndex.from_frame(clss_cols)\n",
    "pre_to_mn_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looking for descending neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_formats = ['png']\n",
    "%matplotlib inline\n",
    "\n",
    "cmap = utils.white_dense()\n",
    "def conn_heat_map(df,xticks,yticks,figsz=[16,16],savefig=False,figfilename=None,cmap=cmap):\n",
    "    fig = plt.figure(1, figsize = figsz)\n",
    "    ax = sns.heatmap(np.log10(df.T.to_numpy()+1), xticklabels=xticks, yticklabels=yticks, cmap=cmap)\n",
    "    cbar = ax.collections[0].colorbar\n",
    "    # here set the labelsize by 20\n",
    "    # cbar.ax.tick_params(labelsize=20)\n",
    "    cbar.set_label(label = 'log 10 # of synapses', size=24)\n",
    "    plt.xlabel('Onto Output neurons', fontsize =18)\n",
    "    plt.ylabel('From input neurons', fontsize =18)\n",
    "    plt.yticks(fontsize = 16)\n",
    "    plt.xticks(fontsize = 16)\n",
    "    plt.show()\n",
    "    if savefig:\n",
    "        if figfilename is None:\n",
    "            figfilename = 'flexor_pool_temp_' + (np.random.randint(10000,99999,size=None)).astype(str)\n",
    "        fig.savefig('./figpanels/' + figfilename + '.svg',format='svg')\n",
    "\n",
    "def lin_heat_map(df,xticks,yticks,figsz=[16,16],savefig=False,figfilename=None,cmap=cmap):\n",
    "    fig = plt.figure(1, figsize = figsz)\n",
    "    ax = sns.heatmap(df.T.to_numpy(), xticklabels=xticks, yticklabels=yticks, cmap=cmap)\n",
    "    cbar = ax.collections[0].colorbar\n",
    "    # here set the labelsize by 20\n",
    "    # cbar.ax.tick_params(labelsize=20)\n",
    "    cbar.set_label(label = 'linear', size=24)\n",
    "    plt.xlabel('Onto Output neurons', fontsize =18)\n",
    "    plt.ylabel('From input neurons', fontsize =18)\n",
    "    plt.yticks(fontsize = 16)\n",
    "    plt.xticks(fontsize = 16)\n",
    "    plt.show()\n",
    "    if savefig:\n",
    "        if figfilename is None:\n",
    "            figfilename = 'flexor_pool_temp_' + (np.random.randint(10000,99999,size=None)).astype(str)\n",
    "        fig.savefig('./figpanels/' + figfilename + '.svg',format='svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_df = pre_to_mn_df.loc['descending']\n",
    "desc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pools = \n",
    "\n",
    "conn_heat_map(df=desc_df, xticks=desc_df.column.get_level_values('preferred_pool'),yticks=pools,figsz=[4,16])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Location of Femur inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mft = \n",
    "mft_conn_mat = pre_to_mn_df.loc[:,mpool_dict['main_tibia_flexor_muscle']]\n",
    "mft_root_ids = mft_conn_mat.columns.get_level_values('segID').to_list()\n",
    "mft_root_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Tibia flexors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = 3\n",
    "layer_name = 'flexor_input'\n",
    "purples = ['#4b006e', '#7e1e9c', '#bf77f6', '#c79fef', 'eecffe']\n",
    "\n",
    "synapse_df = client.materialize.synapse_query(post_ids = mft_root_ids,timestamp = connectome_create.get_timestamp())\n",
    "v = synapse_df.pre_pt_root_id.value_counts()\n",
    "synapse_df = synapse_df[synapse_df.pre_pt_root_id.isin(v.index[v.gt(thresh)])]\n",
    "\n",
    "# variables to render in neuroglancer link\n",
    "\n",
    "rng = np.random.default_rng()\n",
    "rng_idx = rng.permutation(range(synapse_df.shape[0]))\n",
    "render_synapses = synapse_df.iloc[rng_idx[0:5000],:]\n",
    "# render_synapses = synapse_df\n",
    "print(render_synapses.shape)\n",
    "render_neurons = mft_root_ids\n",
    "\n",
    "from nglui.statebuilder import *\n",
    "\n",
    "img_source = client.info.image_source()\n",
    "img_layer = nglui.statebuilder.ImageLayerConfig(name='fanc_v4',\n",
    "                             source=img_source,\n",
    "                             )\n",
    "seg_source = client.info.segmentation_source()\n",
    "\n",
    "seg_layer = nglui.statebuilder.SegmentationLayerConfig(name = 'seg',\n",
    "                                    source = seg_source,\n",
    "                                    fixed_ids = render_neurons)\n",
    "points = nglui.statebuilder.PointMapper(point_column='post_pt_position') ######################## change this to toggle rendering of pre- or post- synaptic points\n",
    "anno_layer = nglui.statebuilder.AnnotationLayerConfig(name=str(layer_name), \n",
    "                                   mapping_rules=points ) # color = purples[i]\n",
    "\n",
    "sb = nglui.statebuilder.StateBuilder([img_layer, seg_layer, anno_layer], resolution=[4.3,4.3,45])\n",
    "# sb.render_state(render_synapses, return_as='html')\n",
    "nglui.statebuilder.helpers.make_url_robust(render_synapses,sb,client,shorten='always')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extensors Tibia "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mft = \n",
    "eti_conn_mat = pre_to_mn_df.loc[:,mpool_dict['tibia_extensor']]\n",
    "eti_root_ids = eti_conn_mat.columns.get_level_values('segID').to_list()\n",
    "print(eti_root_ids)\n",
    "\n",
    "thresh = 3\n",
    "layer_name = 'flexor_input'\n",
    "purples = ['#4b006e', '#7e1e9c', '#bf77f6', '#c79fef', 'eecffe']\n",
    "\n",
    "synapse_df = client.materialize.synapse_query(post_ids = eti_root_ids,timestamp = connectome_create.get_timestamp())\n",
    "v = synapse_df.pre_pt_root_id.value_counts()\n",
    "synapse_df = synapse_df[synapse_df.pre_pt_root_id.isin(v.index[v.gt(thresh)])]\n",
    "\n",
    "# variables to render in neuroglancer link\n",
    "\n",
    "rng = np.random.default_rng()\n",
    "rng_idx = rng.permutation(range(synapse_df.shape[0]))\n",
    "render_synapses = synapse_df.iloc[rng_idx[0:5000],:]\n",
    "# render_synapses = synapse_df\n",
    "print(render_synapses.shape)\n",
    "render_neurons = eti_root_ids\n",
    "\n",
    "from nglui.statebuilder import *\n",
    "\n",
    "img_source = client.info.image_source()\n",
    "img_layer = nglui.statebuilder.ImageLayerConfig(name='fanc_v4',\n",
    "                             source=img_source,\n",
    "                             )\n",
    "seg_source = client.info.segmentation_source()\n",
    "\n",
    "seg_layer = nglui.statebuilder.SegmentationLayerConfig(name = 'seg',\n",
    "                                    source = seg_source,\n",
    "                                    fixed_ids = render_neurons)\n",
    "points = nglui.statebuilder.PointMapper(point_column='post_pt_position') ######################## change this to toggle rendering of pre- or post- synaptic points\n",
    "anno_layer = nglui.statebuilder.AnnotationLayerConfig(name=str(layer_name), \n",
    "                                   mapping_rules=points ) # color = purples[i]\n",
    "\n",
    "sb = nglui.statebuilder.StateBuilder([img_layer, seg_layer, anno_layer], resolution=[4.3,4.3,45])\n",
    "# sb.render_state(render_synapses, return_as='html')\n",
    "nglui.statebuilder.helpers.make_url_robust(render_synapses,sb,client,shorten='always')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aux Flexors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mft = \n",
    "auxA_conn_mat = pre_to_mn_df.loc[:,mpool_dict['auxiliary_tibia_flexor_A']]\n",
    "auxA_root_ids = auxA_conn_mat.columns.get_level_values('segID').to_list()\n",
    "print(auxA_root_ids)\n",
    "\n",
    "thresh = 3\n",
    "layer_name = 'flexor_input'\n",
    "purples = ['#4b006e', '#7e1e9c', '#bf77f6', '#c79fef', 'eecffe']\n",
    "\n",
    "synapse_df = client.materialize.synapse_query(post_ids = auxA_root_ids,timestamp = connectome_create.get_timestamp())\n",
    "v = synapse_df.pre_pt_root_id.value_counts()\n",
    "synapse_df = synapse_df[synapse_df.pre_pt_root_id.isin(v.index[v.gt(thresh)])]\n",
    "\n",
    "# variables to render in neuroglancer link\n",
    "\n",
    "rng = np.random.default_rng()\n",
    "rng_idx = rng.permutation(range(synapse_df.shape[0]))\n",
    "render_synapses = synapse_df.iloc[rng_idx[0:5000],:]\n",
    "# render_synapses = synapse_df\n",
    "print(render_synapses.shape)\n",
    "render_neurons = auxA_root_ids\n",
    "\n",
    "from nglui.statebuilder import *\n",
    "\n",
    "img_source = client.info.image_source()\n",
    "img_layer = nglui.statebuilder.ImageLayerConfig(name='fanc_v4',\n",
    "                             source=img_source,\n",
    "                             )\n",
    "seg_source = client.info.segmentation_source()\n",
    "\n",
    "seg_layer = nglui.statebuilder.SegmentationLayerConfig(name = 'seg',\n",
    "                                    source = seg_source,\n",
    "                                    fixed_ids = render_neurons)\n",
    "points = nglui.statebuilder.PointMapper(point_column='post_pt_position') ######################## change this to toggle rendering of pre- or post- synaptic points\n",
    "anno_layer = nglui.statebuilder.AnnotationLayerConfig(name=str(layer_name), \n",
    "                                   mapping_rules=points ) # color = purples[i]\n",
    "\n",
    "sb = nglui.statebuilder.StateBuilder([img_layer, seg_layer, anno_layer], resolution=[4.3,4.3,45])\n",
    "# sb.render_state(render_synapses, return_as='html')\n",
    "nglui.statebuilder.helpers.make_url_robust(render_synapses,sb,client,shorten='always')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proximal vs distal motor pools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_synapses_onto_pools(render_neurons,syn_df_dict,clr_dict): # #F6921E\n",
    "\n",
    "    img_layer = ngstbld.ImageLayerConfig(name='fanc_v4',\n",
    "                                 source=client.info.image_source(),\n",
    "                                 )\n",
    "    seg_layer = ngstbld.SegmentationLayerConfig(name = 'seg',\n",
    "                                        source =  client.info.segmentation_source(),\n",
    "                                        fixed_ids = render_neurons)\n",
    "\n",
    "    sb1 = ngstbld.StateBuilder(layers=[img_layer, seg_layer], client=client, resolution=[4.3,4.3,45])\n",
    "    state_builders = [sb1]\n",
    "\n",
    "    df_list = [None]\n",
    "\n",
    "    for key in syn_df_dict.keys():\n",
    "        print('layer {}'.format(key))\n",
    "        # pool_points = ngstbld.PointMapper(point_column='pre_pt_position') ######################## change this to toggle rendering of pre- or post- synaptic points\n",
    "        pool_spheres = ngstbld.SphereMapper(center_column='post_pt_position', radius_column='radius')\n",
    "        pool_layer = ngstbld.AnnotationLayerConfig(name=key,\n",
    "                                        mapping_rules=pool_spheres,\n",
    "                                        linked_segmentation_layer=seg_layer.name,\n",
    "                                        color=clr_dict[key] )\n",
    "        sb_pool = ngstbld.StateBuilder(layers=[pool_layer],client=client)\n",
    "        state_builders.append(sb_pool)\n",
    "\n",
    "        df = syn_df_dict[key]\n",
    "        # df.loc[:,'radius'] = int(200)\n",
    "        df_list.append(df)\n",
    "\n",
    "    sb=ngstbld.ChainedStateBuilder(statebuilders=state_builders)\n",
    "    # state = sb.render_state(data_list=[ach_df,gaba_df,glu_df],return_as='dict')\n",
    "\n",
    "    print('{} sbs, {} dfs'.format(len(state_builders),len(df_list)))\n",
    "\n",
    "    state = sb.render_state(data_list=df_list,return_as='dict')\n",
    "    state_id = client.state.upload_state_json(state)\n",
    "\n",
    "    DEFAULT_NGL = \"https://neuromancer-seung-import.appspot.com/\"\n",
    "\n",
    "    url = client.state.build_neuroglancer_url(state_id, ngl_url=DEFAULT_NGL)\n",
    "\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go pool by pool\n",
    "All = slice(None)\n",
    "timestamp = connectome_create.get_timestamp()\n",
    "\n",
    "pool_keys = [\n",
    "    # 'thorax_stance',\n",
    "    'thorax_swing',\n",
    "    # 'tergotrochanter',\n",
    "    # 'trochanter_extensor',\n",
    "    # 'extracoxal_trochanter_depressor',\n",
    "    # 'trochanter_extension',\n",
    "    # 'trochanter_flexion',\n",
    "    # 'femur_reductor',\n",
    "    # 'tibia_extensor',\n",
    "    # 'main_tibia_flexor_muscle',      # main_tibia_flexor for both main and A groups, or main_tibia_flexor_muscle for the muscle\n",
    "    # 'auxiliary_tibia_flexor_A',\n",
    "    # 'auxiliary_tibia_flexor_B',\n",
    "    # 'auxiliary_tibia_flexor_E',\n",
    "    # 'ltm',\n",
    "    # 'tarsus_depressor_med_venU',\n",
    "    # 'tarsus_depressor_noid',\n",
    "    ]\n",
    "pool_clrs = {\n",
    "    'thorax_stance':'#C900C7',\n",
    "    'thorax_swing':'#00BFD4',\n",
    "    'tergotrochanter': '#CCC000',\n",
    "    'extracoxal_trochanter_depressor':'#EEC000',\n",
    "    'trochanter_extensor':'#E9821D',\n",
    "    'trochanter_extensor':'#FFBB8D',\n",
    "    'trochanter_extension':'#203789',\n",
    "    'trochanter_flexion':'#9FB7D3',\n",
    "    'femur_reductor':'#EC1C24',\n",
    "    'tibia_extensor':'#F6921E',\n",
    "    'main_tibia_flexor_muscle':'#203789',\n",
    "    'auxiliary_tibia_flexor_A':'#8CF27C',\n",
    "    'auxiliary_tibia_flexor_B':'#2CEF0A',\n",
    "    'auxiliary_tibia_flexor_E':'#2DB515',\n",
    "    'ltm':'#FFF100',\n",
    "    'tarsus_depressor_med_venU':'#CECECE',\n",
    "    'tarsus_depressor_noid':'#CECECE',\n",
    "}\n",
    "\n",
    "pool_numbers = {\n",
    "    'thorax_stance':'#C900C7',\n",
    "    'thorax_swing':5000,\n",
    "    'tergotrochanter': '#CCC000',\n",
    "    'extracoxal_trochanter_depressor':'#EEC000',\n",
    "    'trochanter_extensor':'#E9821D',\n",
    "    'trochanter_extensor':'#E9821D',\n",
    "    'trochanter_extension':'#203789',\n",
    "    'trochanter_flexion':2500,\n",
    "    'femur_reductor':5000,\n",
    "    'tibia_extensor':5000,\n",
    "    'main_tibia_flexor_muscle':2500,\n",
    "    'auxiliary_tibia_flexor_A':'#8CF27C',\n",
    "    'auxiliary_tibia_flexor_B':'#2CEF0A',\n",
    "    'auxiliary_tibia_flexor_E':'#2DB515',\n",
    "    'ltm':'#FFF100',\n",
    "    'tarsus_depressor_med_venU':5000,\n",
    "    'tarsus_depressor_noid':'#CECECE',\n",
    "}\n",
    "\n",
    "thresh = 3\n",
    "\n",
    "# use a list of strings for all the html strings\n",
    "ngst_dict = {}\n",
    "for pk in pool_keys:    \n",
    "    print(pk)\n",
    "    \n",
    "    mns_df = pre_to_mn_df.loc[:,mpool_dict[pk]]\n",
    "    mn_root_ids = mns_df.columns.get_level_values('segID').to_list()\n",
    "    print(mn_root_ids)\n",
    "\n",
    "    syn_df_dict = {}\n",
    "    clr_dict = {}\n",
    "    cnt = 0;\n",
    "\n",
    "    N_syn = 2500\n",
    "\n",
    "    # if len(mn_root_ids)>3:\n",
    "    #     mn_roots_1 = mn_root_ids[-3:]\n",
    "    #     print(mn_roots_1)\n",
    "\n",
    "    #     mn_roots_2 = mn_root_ids[:-3]\n",
    "    # else:\n",
    "    #     mn_roots_1 = mn_root_ids\n",
    "    #     mn_roots_2 = []\n",
    "\n",
    "    for n in reversed(mn_root_ids):\n",
    "        # mn_df = mns_df.loc[:,(All,All,All,All,All,n)]\n",
    "        try:\n",
    "            synapse_df = client.materialize.synapse_query(post_ids = n,timestamp = connectome_create.get_timestamp())\n",
    "        except ValueError:\n",
    "            synapse_df = client.materialize.synapse_query(post_ids = n)\n",
    "        if synapse_df.shape[0]==0:\n",
    "            synapse_df = client.materialize.synapse_query(post_ids = 648518346491655185)\n",
    "        v = synapse_df.pre_pt_root_id.value_counts()\n",
    "        synapse_df = synapse_df[synapse_df.pre_pt_root_id.isin(v.index[v.gt(thresh)])]\n",
    "        synapse_df.loc[:,'radius'] = int(100)\n",
    "\n",
    "        # reduce the number of points in synapse_df\n",
    "        rng = np.random.default_rng()\n",
    "        rng_idx = rng.permutation(range(synapse_df.shape[0]))\n",
    "        render_synapses = synapse_df.iloc[rng_idx[0:pool_numbers[pk]],:]\n",
    "        # render_synapses = synapse_df\n",
    "        print(render_synapses.shape)\n",
    "\n",
    "        key = pk + str(n)\n",
    "        syn_df_dict[key] = render_synapses\n",
    "        clr_dict[key]  = pool_clrs[pk]\n",
    "\n",
    "        cnt = cnt+1\n",
    "        \n",
    "        if cnt>2:\n",
    "            pass\n",
    "            # break\n",
    "\n",
    "    ngst_dict[pk] = build_synapses_onto_pools(mn_root_ids,syn_df_dict,clr_dict)\n",
    "    print(ngst_dict[pk])\n",
    "\n",
    "    # syn_df_dict = {}\n",
    "    # clr_dict = {}\n",
    "\n",
    "    # if mn_roots_2:\n",
    "    #     print(mn_roots_2)\n",
    "    #     for n in reversed(mn_root_ids[0:-3]):\n",
    "    #         # mn_df = mns_df.loc[:,(All,All,All,All,All,n)]\n",
    "    #         try:\n",
    "    #             synapse_df = client.materialize.synapse_query(post_ids = n,timestamp = connectome_create.get_timestamp())\n",
    "    #         except ValueError:\n",
    "    #             synapse_df = client.materialize.synapse_query(post_ids = n)\n",
    "    #         v = synapse_df.pre_pt_root_id.value_counts()\n",
    "    #         synapse_df = synapse_df[synapse_df.pre_pt_root_id.isin(v.index[v.gt(thresh)])]\n",
    "    #         synapse_df.loc[:,'radius'] = int(100)\n",
    "\n",
    "    #         # reduce the number of points in synapse_df\n",
    "    #         rng = np.random.default_rng()\n",
    "    #         rng_idx = rng.permutation(range(synapse_df.shape[0]))\n",
    "    #         render_synapses = synapse_df.iloc[rng_idx[0:5000],:]\n",
    "    #         # render_synapses = synapse_df\n",
    "    #         print(render_synapses.shape)\n",
    "\n",
    "    #         key = pk + str(n)\n",
    "    #         syn_df_dict[key] = render_synapses\n",
    "    #         clr_dict[key]  = pool_clrs[pk]\n",
    "\n",
    "    #         cnt = cnt+1\n",
    "            \n",
    "    #         if cnt>2:\n",
    "    #             pass\n",
    "    #             # break\n",
    "    #     pk_2 = pk + '_2'\n",
    "    #     ngst_dict[pk_2] = build_synapses_onto_pools(mn_root_ids,syn_df_dict,clr_dict)\n",
    "    #     print(ngst_dict[pk_2])\n",
    "\n",
    "ngst_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synapse_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synapse_df = client.materialize.synapse_query(post_ids = n,timestamp=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.0 ('fanc_analysis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "701379af8fa9566edb753273e8a4cc72928f1706e0a9299fef0231c034742a95"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
