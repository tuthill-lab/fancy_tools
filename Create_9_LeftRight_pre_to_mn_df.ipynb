{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query timestamp: 2022-08-31 00:00:00\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import utils\n",
    "import connectome_create\n",
    "# viz_method = one of ['itkwidgets', 'vtk']\n",
    "viz_method = 'vtk'\n",
    "\n",
    "# import some of our favorite packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sea\n",
    "import re\n",
    "import warnings\n",
    "\n",
    "%matplotlib inline\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import nglui.statebuilder as ngstbld\n",
    "\n",
    "# this is the EM specific package for querying the EM data\n",
    "from caveclient import CAVEclient\n",
    "\n",
    "from datetime import date\n",
    "from meshparty import trimesh_io, trimesh_vtk\n",
    "from meshparty import skeletonize, skeleton_io, skeleton\n",
    "import cloudvolume\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "with open(Path.home() / '.cloudvolume/secrets/'/'cave-secret.json') as f:\n",
    "        tokens = json.load(f)\n",
    "        \n",
    "seg_source = 'graphene://https://cave.fanc-fly.com/segmentation/table/mar2021_prod'\n",
    "cv = cloudvolume.CloudVolume(cloudpath=seg_source, use_https=True, secrets=tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datastack_name = 'fanc_production_mar2021'\n",
    "\n",
    "client = CAVEclient(datastack_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# client = CAVEclient()\n",
    "\n",
    "# # if not os.path.isfile(os.path.expanduser(\"~/.cloudvolume/secrets/cave-secret.json\")):\n",
    "# client.auth.get_new_token(open=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you have not yet setup this computer, uncomment this below line\n",
    "# paste the token from the website in, and run the line\n",
    "\n",
    "# client.auth.save_token(token=\"c14cd7a3e18a1a697716a399afbf5778\", overwrite=True)\n",
    "\n",
    "# then comment or delete the line as you don't need to run it on this computer  again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_to_mn_df = connectome_create.left_pre_to_mn_df(client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query the annotation table 'motor_neuron_table_v7' \n",
    "'motor_neuron_table_v2' contains a list of all the right and left motor neurons in T1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.materialize.get_tables()\n",
    "t1_mns_df = client.materialize.query_table('motor_neuron_table_v7')\n",
    "soma_table = client.materialize.query_table('soma_jan2022')\n",
    "sensory_axons = client.materialize.query_table('sensory_axon_table')\n",
    "\n",
    "t1_mns_df.head(70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensory_axons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sides = sorted([*{*side}])\n",
    "nerves = sorted([*{*nerve}])\n",
    "segments = sorted([*{*segment}])\n",
    "fcns = sorted([*{*function}])\n",
    "\n",
    "pre_to_mn_df = None\n",
    "\n",
    "for sd in sides:\n",
    "    mnmi_side = utils.multiindex_include(mn_index,[sd])\n",
    "    for nrv in nerves: # ['Leg']:\n",
    "        mnmi_side_nrv = utils.multiindex_include(mnmi_side,[nrv])\n",
    "        segs = mnmi_side_nrv.get_level_values('segment').to_list()\n",
    "        segs = sorted([*{*segs}])\n",
    "        for sg in segs:\n",
    "            mnmi_side_nrv_seg = utils.multiindex_include(mnmi_side_nrv,[sg])\n",
    "            segfcns = mnmi_side_nrv_seg.get_level_values('function').to_list()\n",
    "            segfcns = sorted([*{*segfcns}])\n",
    "            for fcn in segfcns:\n",
    "                mnmi_side_nrv_seg_fcn = utils.multiindex_include(mnmi_side_nrv_seg,[fcn])\n",
    "\n",
    "                print('({}, {}, {}, {})'.format(sd,nrv,sg,fcn))\n",
    "\n",
    "                # get the resulting segIDs\n",
    "                mn_segIDs = mnmi_side_nrv_seg_fcn.get_level_values('segID').to_list()\n",
    "\n",
    "                # Query the synapse table\n",
    "                mn_inputs_df = client.materialize.synapse_query(post_ids = mn_segIDs) # Takes list\n",
    "                mn_inputs_df['has_soma'] = mn_inputs_df.pre_pt_root_id.isin(soma_table.pt_root_id)\n",
    "                mn_inputs_df['sensory'] = mn_inputs_df.pre_pt_root_id.isin(sensory_axons.pt_root_id)\n",
    "                mn_inputs_df['sensory'] = mn_inputs_df.pre_pt_root_id.isin(sensory_axons.pt_root_id)\n",
    "                print(mn_inputs_df.shape)\n",
    "\n",
    "                mn_inputs_df = utils.group_and_count_inputs(mn_inputs_df,3)\n",
    "                partner_df = utils.create_pre_post_df(mn_inputs_df,mnmi_side_nrv_seg_fcn)\n",
    "\n",
    "                if pre_to_mn_df is None:\n",
    "                    pre_to_mn_df = partner_df\n",
    "                else:\n",
    "                    # preserve the order of premotor neurons from most connected down\n",
    "                    curidx = pre_to_mn_df.index.to_list()\n",
    "                    newidx = partner_df.index.to_list()\n",
    "                    for segid in newidx:\n",
    "                        if segid not in curidx:\n",
    "                            curidx.append(segid)\n",
    "                    pre_to_mn_df = pd.concat([pre_to_mn_df,partner_df],axis=1,join='outer').reindex(index=curidx).fillna(value=0,downcast='infer')\n",
    "\n",
    "mn_multidx = pre_to_mn_df.columns           \n",
    "pre_to_mn_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Order according to segment (thorax, coxa, etc) and function (flex, extend, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize matrix\n",
    "mn_multidx = mn_multidx\n",
    "mn_labels = mn_multidx.get_level_values('muscle').to_list()\n",
    "mn_segment = mn_multidx.get_level_values('segment').to_list()\n",
    "mn_fcn = mn_multidx.get_level_values('function').to_list()\n",
    "mn_rank = mn_multidx.get_level_values('rank').to_list()\n",
    "idx = [str(i) for i in range(len(mn_fcn))]\n",
    "mn_rank = [str(i) for i in mn_rank]\n",
    "lbls = [i + '_' + j + '_' + k + '_' + l + '_' + n for i, j, k, l, n in zip(idx, mn_segment, mn_fcn, mn_labels,mn_rank)]\n",
    "lbls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reorder_bysegfcn = utils.get_segment_fcn_order(side='')\n",
    "np.array(lbls)[reorder_bysegfcn].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bristle_id = 648518346480454913\n",
    "# pmn = pmnsegids[0:10]\n",
    "# #Downloading Mesh\n",
    "# pmn_cv_mesh = cv.mesh.get(pmn, remove_duplicate_vertices=True,use_byte_offsets=True)[pmn]\n",
    "# mp_pmn = trimesh_io.Mesh(pmn_cv_mesh.vertices,pmn_cv_mesh.faces,pmn_cv_mesh.normals)\n",
    "# print(pmn_cv_mesh.vertices.shape,pmn_cv_mesh.faces.shape,pmn_cv_mesh.normals.shape)\n",
    "\n",
    "# max_dist = 1000\n",
    "# dist_step=500\n",
    "# ccs = scipy.sparse.csgraph.connected_components(mp_bristle.csgraph)\n",
    "# ccs_u, cc_sizes = np.unique(ccs[1], return_counts=True)\n",
    "# large_cc_ids = ccs_u[cc_sizes > 70]\n",
    "# print(len(large_cc_ids))\n",
    "\n",
    "# kdtrees = []\n",
    "# vertex_ids = []\n",
    "# for cc_id in large_cc_ids:\n",
    "#     m = ccs[1] == cc_id\n",
    "#     vertex_ids.append(np.where(m)[0])\n",
    "#     v = mp_bristle.vertices[m]\n",
    "#     kdtrees.append(spatial.cKDTree(v))\n",
    "\n",
    "# add_edges = []\n",
    "# for i_tree in range(len(large_cc_ids) - 1):\n",
    "#     for j_tree in range(i_tree + 1, len(large_cc_ids)):\n",
    "#         print(\"%d - %d      \" % (i_tree, j_tree), end=\"\\r\")\n",
    "\n",
    "#         if np.any(kdtrees[i_tree].query_ball_tree(kdtrees[j_tree], max_dist)):\n",
    "#             for this_dist in range(dist_step, max_dist + dist_step, dist_step):\n",
    "\n",
    "#                 pairs = kdtrees[i_tree].query_ball_tree(kdtrees[j_tree],\n",
    "#                                                         this_dist)\n",
    "\n",
    "#                 if np.any(pairs):\n",
    "#                     for i_p, p in enumerate(pairs):\n",
    "#                         if len(p) > 0:\n",
    "#                             add_edges.extend([[vertex_ids[i_tree][i_p],\n",
    "#                                                vertex_ids[j_tree][v]]\n",
    "#                                               for v in p])\n",
    "#                     break\n",
    "# if len(add_edges) >0:\n",
    "#     if large_cc_ids[1].size >0:\n",
    "\n",
    "### Creating a Meshwork Object\n",
    "#Depending your skeleton you may want to play around with the max_dist and other parameters. If you get an error about \n",
    "# 0 indices being merged, uncomment the code above and try that.\n",
    "# mp_pmn.merge_large_components(max_dist=1000)\n",
    "# in_comp = mesh_filters.filter_largest_component(mp_pmn)\n",
    "# bristle_anchor = mp_bristle.apply_mask(in_comp)\n",
    "# bristle_mw = meshwork.Meshwork(bristle_anchor, seg_id=bristle_id,voxel_resolution=[4.3,4.3,45])\n",
    "\n",
    "# ## Skeletonizing\n",
    "# ##I set the entry point as \"soma_point\" so that I can control the root, you can point any point you choose there or none\n",
    "# #entry_pt = bristle_entry_points.entry_point_nm[bristle_entry_points['Description'] == bristle_id].tolist()[0]\n",
    "# bristle_mw.skeletonize_mesh(entry_pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slice entire data frame to find particular segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "All = slice(None)\n",
    "pre_to_mn_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Premotor neurons with SOMA: pre_wsoma_to_mn_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_wsoma_to_mn_df = pre_to_mn_df.loc[(All, True), :]\n",
    "pre_wsoma_to_mn_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fragments with NO SOMA: pre_nosoma_to_mn_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_nosoma_to_mn_df = pre_to_mn_df.loc[(All, False), :]\n",
    "pre_nosoma_to_mn_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Left with soma: pre_soma_to_mn_L_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pre_wsoma_to_mn_L_df = pre_to_mn_df.loc[(All, True), ('L')]\n",
    "pre_wsoma_to_mn_L_df.shape\n",
    "numinputs = pre_wsoma_to_mn_L_df.sum(axis=1)\n",
    "pre_wsoma_to_mn_L_df = pre_wsoma_to_mn_L_df.loc[numinputs>0,:]\n",
    "pre_wsoma_to_mn_L_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Right with soma: pre_soma_to_mn_R_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pre_wsoma_to_mn_R_df = pre_to_mn_df.loc[(All, True), ('R')]\n",
    "pre_wsoma_to_mn_R_df.shape\n",
    "numinputs = pre_wsoma_to_mn_R_df.sum(axis=1)\n",
    "pre_wsoma_to_mn_R_df = pre_wsoma_to_mn_R_df.loc[numinputs>0,:]\n",
    "pre_wsoma_to_mn_R_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do numbers of objects change over time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Watch the number of objects with a soma increase\n",
    "import datetime\n",
    "\n",
    "datearr = [\n",
    "    datetime.date(2022,4,20),\n",
    "    datetime.date(2022,4,22),\n",
    "    datetime.date(2022,4,25),\n",
    "    datetime.date(2022,5,2)\n",
    "]\n",
    "NsegWsoma = [1770,1775,1782,1802]\n",
    "NsegNoSoma = [np.nan,5646,5642,5599]\n",
    "\n",
    "arrays = [\n",
    "    datearr,\n",
    "    NsegWsoma,\n",
    "    NsegNoSoma,\n",
    "        ]\n",
    "\n",
    "fig = plt.figure(1, figsize=(12, 6))\n",
    "ax1 = plt.subplot2grid((1,2),(0,0))\n",
    "\n",
    "ax1.scatter(datearr, NsegWsoma)\n",
    "plt.sca(ax1)\n",
    "plt.ylabel('soma-attached objects')\n",
    "plt.xlabel('date')\n",
    "plt.title('Objects with somas')\n",
    "\n",
    "ax2 = plt.subplot2grid((1,2),(0,1))\n",
    "ax2.scatter(datearr, NsegNoSoma)\n",
    "plt.ylabel('soma-attached objects')\n",
    "plt.xlabel('date')\n",
    "plt.title('Objects without somas')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Premotors with somas that provide input to both right and left MNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numLinputs = np.array(pre_wsoma_to_mn_df.loc[(All, True), ('L')].sum(axis=1).tolist())\n",
    "numRinputs = np.array(pre_wsoma_to_mn_df.loc[(All, True), ('R')].sum(axis=1).tolist())\n",
    "bothinputs = (numLinputs >0) & (numRinputs >0)# numRinputs.ge(1)\n",
    "pre_to_RL_mn_df = pre_wsoma_to_mn_df.loc[bothinputs,:]\n",
    "\n",
    "# eliminate blank synapses\n",
    "numinputs = np.array(pre_to_RL_mn_df.sum(axis=0).tolist())\n",
    "pre_to_RL_mn_df = pre_to_RL_mn_df.loc[:,numinputs>0]\n",
    "\n",
    "pre_to_RL_mn_df\n",
    "today = date.today()\n",
    "d1 = today.strftime(\"%Y%m%d\")\n",
    "pre_to_RL_mn_df.to_csv('./saved_dfs/preMNsTargetingRandL' + d1 + '.csv')\n",
    "print(pre_to_RL_mn_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Compare the number of connections onto left and right neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.text as text\n",
    "\n",
    "numLinputs = np.array(pre_wsoma_to_mn_df.loc[(All, True), ('L')].sum(axis=1).tolist())\n",
    "numRinputs = np.array(pre_wsoma_to_mn_df.loc[(All, True), ('R')].sum(axis=1).tolist())\n",
    "bothinputs = (numLinputs >0) & (numRinputs >0)# numRinputs.ge(1)\n",
    "pre_to_RL_mn_df = pre_wsoma_to_mn_df.loc[bothinputs,:]\n",
    "\n",
    "numinputs = np.array(pre_to_RL_mn_df.sum(axis=0).tolist())\n",
    "pre_to_RL_mn_df = pre_to_RL_mn_df.loc[:,numinputs>0]\n",
    "\n",
    "leftinputs = pre_to_RL_mn_df.loc[All,('L')].sum(axis=1).to_numpy()\n",
    "rightinputs = pre_to_RL_mn_df.loc[All,('R')].sum(axis=1).to_numpy()\n",
    "\n",
    "lorder = np.flip(np.argsort(leftinputs))\n",
    "li = leftinputs[lorder]\n",
    "ri = rightinputs[lorder]\n",
    "rlpms = pre_to_RL_mn_df.index.get_level_values('segID').to_numpy()\n",
    "rlpms = rlpms[lorder]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_to_RL_mn_df.iloc[lorder,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [str(i) for i in rlpms]\n",
    "labels[0] = 'ascend.'\n",
    "labels[1] = 'm to l'\n",
    "labels[1] = 'm to l'\n",
    "labels[4] = 'ascend.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check out a few interesting RL neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmn_syn = client.materialize.synapse_query(pre_ids = rlpms[idx]) # Takes list\n",
    "# client.materialize.synapse_query?\n",
    "print(pmn_syn.shape)\n",
    "pmn_syn_w_mn = pmn_syn.post_pt_root_id.isin(pre_to_RL_mn_df.columns.get_level_values('segID'))\n",
    "pmn_syn = pmn_syn.loc[pmn_syn_w_mn,:]\n",
    "pmn_syn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a neuroglancer link with a synapse layer\n",
    "# Modified from Leila\n",
    "import nglui.statebuilder as ngstbld\n",
    "\n",
    "# variables to render in neuroglancer link\n",
    "render_synapses = pmn_syn\n",
    "render_neurons = [rlpms[idx]]\n",
    "\n",
    "img_source = client.info.image_source()\n",
    "img_layer = ngstbld.ImageLayerConfig(name='fanc_v4',\n",
    "                             source=img_source,\n",
    "                             )\n",
    "seg_source = client.info.segmentation_source()\n",
    "\n",
    "seg_layer = ngstbld.SegmentationLayerConfig(name = 'seg',\n",
    "                                    source = seg_source,\n",
    "                                    fixed_ids = render_neurons)\n",
    "points = ngstbld.PointMapper(point_column='post_pt_position') ######################## change this to toggle rendering of pre- or post- synaptic points\n",
    "anno_layer = ngstbld.AnnotationLayerConfig(name='annos',\n",
    "                                   mapping_rules=points )\n",
    "\n",
    "sb = ngstbld.StateBuilder([img_layer, seg_layer, anno_layer], resolution=[4.3,4.3,45])\n",
    "sb.render_state(render_synapses, return_as='html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(1, figsize=(12, 9))\n",
    "ax1 = plt.subplot2grid((1,1),(0,0))\n",
    "\n",
    "plt.scatter(leftinputs, rightinputs)\n",
    "plt.xlabel('inputs to L MNs')\n",
    "plt.ylabel('inputs to R MNs')\n",
    "plt.title('Presynaptic to L AND R MNs')\n",
    "\n",
    "t = text.Text(li[4]+5, ri[4]+5, labels[4], ha='left', va='bottom',axes = ax1)\n",
    "ax1.add_artist(t)\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_to_mn_dfto_numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cosine similarity comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute cosine similarity, then cluster using agglomerative clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.cosine_similarity.html\n",
    "# cosine similarity - K(X, Y) = <X, Y> / (||X||*||Y||)\n",
    "sim_mat = cosine_similarity(pre_wsoma_to_mn_L_df.to_numpy().transpose())\n",
    "\n",
    "# setting distance_threshold=0 ensures we compute the full tree.\n",
    "model = AgglomerativeClustering(distance_threshold=0, n_clusters=None).fit(sim_mat)\n",
    "\n",
    "plt.title(\"Hierarchical Clustering Dendrogram\")\n",
    "# plot the top three levels of the dendrogram\n",
    "clustered_order = utils.plot_dendrogram(model, truncate_mode=\"level\", p=12) # p truncate mode\n",
    "clustered_order = np.array(clustered_order).astype(int) # convert strins into integers\n",
    "print(clustered_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reordered_wsoma_df = pre_wsoma_to_mn_L_df.iloc[:,clustered_order]\n",
    "#reordered_mn_df = pre_to_mn_df.iloc[:,clustered_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_mat = cosine_similarity(reordered_wsoma_df.to_numpy().transpose())\n",
    "ro_multidx = reordered_wsoma_df.columns\n",
    "\n",
    "# visualize matrix\n",
    "mn_labels = ro_multidx.get_level_values('muscle').to_list()\n",
    "mn_rank = ro_multidx.get_level_values('rank').to_list()\n",
    "mn_ids = ro_multidx.get_level_values('segID').to_list()\n",
    "idx = [str(i) for i in range(len(mn_ids))]\n",
    "sid = [str(i) for i in mn_ids]\n",
    "mn_rank = [str(i) for i in mn_rank]\n",
    "lbls = [i + '_' + j + '_' + k + '_' + l for i, j, k, l in zip(mn_labels, mn_rank, sid, idx,)]\n",
    "\n",
    "fig = plt.figure(1, figsize = [20,18])\n",
    "ax = sea.heatmap(sim_mat, xticklabels=mn_ids, yticklabels=lbls)\n",
    "ax.xaxis.set_ticks_position('top')\n",
    "cbar = ax.collections[0].colorbar\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation = 90)\n",
    "\n",
    "# here set the labelsize by 20\n",
    "cbar.ax.tick_params(labelsize=20)\n",
    "cbar.set_label(label = 'cosine similarity', size=24)\n",
    "plt.xlabel('Motor Neurons', fontsize =18)\n",
    "plt.ylabel('Motor Neurons', fontsize =18)\n",
    "plt.yticks(fontsize = 16)\n",
    "plt.xticks(fontsize = 16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Order according to SEGMENT and FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reorder_idx_bysegfcn = utils.get_segment_fcn_order(side = 'left')\n",
    "pre_wsoma_to_mn_L_df = pre_to_mn_df.loc[(All, True), ('L')]\n",
    "numinputs = pre_wsoma_to_mn_L_df.sum(axis=1)\n",
    "pre_wsoma_to_mn_L_df = pre_wsoma_to_mn_L_df.loc[numinputs>0,:]\n",
    "\n",
    "\n",
    "fig2order_wsoma_df = pre_wsoma_to_mn_L_df.iloc[:,reorder_idx_bysegfcn]\n",
    "#reordered_mn_df = pre_to_mn_df.iloc[:,clustered_order]\n",
    "sim_mat = cosine_similarity(fig2order_wsoma_df.to_numpy().transpose())\n",
    "ro_multidx = fig2order_wsoma_df.columns\n",
    "\n",
    "# visualize matrix\n",
    "mn_labels = ro_multidx.get_level_values('muscle').to_list()\n",
    "mn_rank = ro_multidx.get_level_values('rank').to_list()\n",
    "mn_ids = ro_multidx.get_level_values('segID').to_list()\n",
    "idx = [str(i) for i in range(len(mn_ids))]\n",
    "sid = [str(i) for i in mn_ids]\n",
    "mn_rank = [str(i) for i in mn_rank]\n",
    "lbls = [i + '_' + j + '_' + k + '_' + l for i, j, k, l in zip(mn_labels, mn_rank, sid, idx,)]\n",
    "\n",
    "fig = plt.figure(1, figsize = [20,18])\n",
    "ax = sea.heatmap(sim_mat, xticklabels=mn_ids, yticklabels=lbls)\n",
    "ax.xaxis.set_ticks_position('top')\n",
    "cbar = ax.collections[0].colorbar\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation = 90)\n",
    "\n",
    "# here set the labelsize by 20\n",
    "cbar.ax.tick_params(labelsize=20)\n",
    "cbar.set_label(label = 'cosine similarity', size=24)\n",
    "plt.xlabel('Motor Neurons', fontsize =18)\n",
    "plt.ylabel('Motor Neurons', fontsize =18)\n",
    "plt.yticks(fontsize = 16)\n",
    "plt.xticks(fontsize = 16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cosine similarity of both sides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of input sources WITH SOMA\n",
    "pre_wsoma_to_mn_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reorder_idx_bysegfcn = utils.get_segment_fcn_order()\n",
    "pre_wsoma_to_mn_df = pre_to_mn_df.loc[(All, True), :]\n",
    "fullfig2order_wsoma_df = pre_wsoma_to_mn_df.iloc[:,reorder_idx_bysegfcn]\n",
    "#reordered_mn_df = pre_to_mn_df.iloc[:,clustered_order]\n",
    "sim_mat = cosine_similarity(fullfig2order_wsoma_df.to_numpy().transpose())\n",
    "ro_multidx = fullfig2order_wsoma_df.columns\n",
    "\n",
    "# visualize matrix\n",
    "mn_side = ro_multidx.get_level_values('side').to_list()\n",
    "mn_labels = ro_multidx.get_level_values('muscle').to_list()\n",
    "mn_rank = ro_multidx.get_level_values('rank').to_list()\n",
    "mn_ids = ro_multidx.get_level_values('segID').to_list()\n",
    "idx = [str(i) for i in range(len(mn_ids))]\n",
    "sid = [str(i) for i in mn_ids]\n",
    "mn_rank = [str(i) for i in mn_rank]\n",
    "lbls = [h + '_' + i + '_' + j + '_' + k + '_' + l for h, i, j, k, l in zip(mn_side,mn_labels, mn_rank, sid, idx,)]\n",
    "\n",
    "fig = plt.figure(1, figsize = [20,18])\n",
    "ax = sea.heatmap(sim_mat, xticklabels=mn_ids, yticklabels=lbls)\n",
    "ax.xaxis.set_ticks_position('top')\n",
    "cbar = ax.collections[0].colorbar\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation = 90)\n",
    "\n",
    "# here set the labelsize by 20\n",
    "cbar.ax.tick_params(labelsize=20)\n",
    "cbar.set_label(label = 'cosine similarity', size=24)\n",
    "plt.xlabel('Motor Neurons', fontsize =18)\n",
    "plt.ylabel('Motor Neurons', fontsize =18)\n",
    "plt.yticks(fontsize = 16)\n",
    "plt.xticks(fontsize = 16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printMNstuff(i,mltidx):\n",
    "    idx = mltidx[i]\n",
    "    print(idx)\n",
    "    segids = t1_mns_df.pt_root_id.to_list()\n",
    "    df_i = segids.index(idx[-1])\n",
    "    pnt = t1_mns_df.pt_position[df_i]\n",
    "    print(pnt)\n",
    "    \n",
    "def print_pre_stuff(i,idxlist):\n",
    "    idx = idxlist[i]\n",
    "    print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trochanter promotors\n",
    "printMNstuff(0,ro_multidx) # input to main tibia flexors\n",
    "printMNstuff(1,ro_multidx) # input to main tibia flexors 648518346490952225\n",
    "printMNstuff(2,ro_multidx) # input to main tibia flexors 648518346494806962\n",
    "printMNstuff(3,ro_multidx) # input to main tibia flexors 648518346495328079\n",
    "# 648518346486120840 648518346504764531 648518346500284085 648518346475233889\n",
    "\n",
    "printMNstuff(45,ro_multidx) # input to main tibia flexors 648518346483181988\n",
    "#648518346483181988\n",
    "\n",
    "print('')\n",
    "print('flexors')\n",
    "# Trochanter flexors\n",
    "printMNstuff(4,ro_multidx) # input to main tibia flexors\n",
    "printMNstuff(5,ro_multidx) # input to main tibia flexors 648518346490952225\n",
    "printMNstuff(6,ro_multidx) # input to main tibia flexors 648518346494806962\n",
    "printMNstuff(7,ro_multidx) # input to main tibia flexors 648518346495328079\n",
    "printMNstuff(8,ro_multidx) # input to main tibia flexors 648518346483087268\n",
    "printMNstuff(9,ro_multidx) # input to main tibia flexors 648518346475428480\n",
    "# 648518346478862543 648518346507176223 648518346483112382 648518346489322585 648518346499251291 648518346517668968"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note, these change from instance to instance for some reason\n",
    "# Miller 32 and anterior motor neurons: https://neuromancer-seung-import.appspot.com/?json_url=https://global.daf-apis.com/nglstate/api/v1/4566692181049344\n",
    "printMNstuff(20,ro_multidx) # input to main tibia flexors 648518346486098834 648518346490952225 648518346494806962 648518346495328079 648518346483087268 648518346475428480\n",
    "printMNstuff(21,ro_multidx) # input to main tibia flexors 648518346490952225\n",
    "printMNstuff(22,ro_multidx) # input to main tibia flexors 648518346494806962\n",
    "printMNstuff(23,ro_multidx) # input to main tibia flexors 648518346495328079\n",
    "printMNstuff(24,ro_multidx) # input to main tibia flexors 648518346483087268\n",
    "printMNstuff(25,ro_multidx) # input to main tibia flexors 648518346475428480\n",
    "# 648518346486098834 648518346490952225 648518346494806962 648518346495328079 648518346483087268 648518346475428480\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trochanteral extension (depression): https://neuromancer-seung-import.appspot.com/?json_url=https://global.daf-apis.com/nglstate/api/v1/5678571838242816\n",
    "printMNstuff(51,ro_multidx) # input to main tibia flexors 648518346486706585\n",
    "printMNstuff(52,ro_multidx) # input to main tibia flexors 648518346486706585\n",
    "printMNstuff(53,ro_multidx) # input to main tibia flexors 648518346486706585\n",
    "printMNstuff(54,ro_multidx) # input to main tibia flexors 648518346486706585\n",
    "printMNstuff(55,ro_multidx) # input to main tibia flexors 648518346486706585"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weird trochanter extensor\n",
    "printMNstuff(43,ro_multidx) # \n",
    "printMNstuff(44,ro_multidx) # \n",
    "# 648518346493661944 648518346489611133"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stray small ltms\n",
    "printMNstuff(47,ro_multidx) # \n",
    "# 648518346497452278 648518346489317209"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stray small ltms\n",
    "printMNstuff(0,ro_multidx) # \n",
    "# 648518346497452278 648518346489317209"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Femur ltms\n",
    "printMNstuff(65,ro_multidx) # \n",
    "printMNstuff(66,ro_multidx) # \n",
    "# 648518346493757553 648518346507111240"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connectome of preMNs\n",
    "Premotor neurons can: \n",
    " - have a soma\n",
    "     - local\n",
    "     - intersegmental\n",
    "          - outputs to T1\n",
    "          - mixed inputs/outputs in T1\n",
    "              - more inputs in T1\n",
    "              - more outpus in T1\n",
    "     - ascending\n",
    " - have no soma\n",
    "     - descending\n",
    "     - sensory\n",
    "     - fragments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With somas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ro_multidx = fullfig2order_wsoma_df.columns\n",
    "sim_mat = cosine_similarity(fullfig2order_wsoma_df.to_numpy())\n",
    "\n",
    "# setting distance_threshold=0 ensures we compute the full tree.\n",
    "model = AgglomerativeClustering(distance_threshold=0, n_clusters=None).fit(sim_mat)\n",
    "\n",
    "# plot the top three levels of the dendrogram\n",
    "clustered_order = utils.plot_dendrogram(model, truncate_mode=\"level\", p=6000) # p truncate mode\n",
    "clustered_order = np.array(clustered_order).astype(int) # convert strins into integers\n",
    "# print(clustered_order)\n",
    "reordered_pre_to_mn_df = fullfig2order_wsoma_df.iloc[clustered_order,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_mat = cosine_similarity(reordered_pre_to_mn_df.to_numpy())\n",
    "\n",
    "# visualize matrix\n",
    "mn_labels = ro_multidx.get_level_values('muscle').to_list()\n",
    "mn_rank = ro_multidx.get_level_values('rank').to_list()\n",
    "mn_ids = ro_multidx.get_level_values('segID').to_list()\n",
    "idx = [str(i) for i in range(len(mn_ids))]\n",
    "sid = [str(i) for i in mn_ids]\n",
    "mn_rank = [str(i) for i in mn_rank]\n",
    "lbls = [i + '_' + j + '_' + k + '_' + l for i, j, k, l in zip(mn_labels, mn_rank, sid, idx,)]\n",
    "\n",
    "fig = plt.figure(1, figsize = [20,18])\n",
    "ax = sea.heatmap(sim_mat) #, xticklabels=mn_ids, yticklabels=lbls)\n",
    "# ax.xaxis.set_ticks_position('top')\n",
    "cbar = ax.collections[0].colorbar\n",
    "#ax.set_xticklabels(ax.get_xticklabels(),rotation = 90)\n",
    "\n",
    "# here set the labelsize by 20\n",
    "cbar.ax.tick_params(labelsize=20)\n",
    "cbar.set_label(label = 'cosine similarity', size=24)\n",
    "plt.xlabel('Premotor Neurons', fontsize =18)\n",
    "plt.ylabel('Premotor Neurons', fontsize =18)\n",
    "# plt.yticks(fontsize = 16)\n",
    "# plt.xticks(fontsize = 16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full connectome onto right and left sides. TODO: order by intersegmental vs local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reorder_mn_mat = np.log10(reordered_pre_to_mn_df.to_numpy().transpose()+1)\n",
    "fig = plt.figure(1, figsize = [25,15])\n",
    "ax = sea.heatmap(reorder_mn_mat, yticklabels=lbls) #, cmap=parula_map\n",
    "cbar = ax.collections[0].colorbar\n",
    "# here set the labelsize by 20\n",
    "# cbar.ax.tick_params(labelsize=20)\n",
    "cbar.set_label(label = 'log 10 # of synapses', size=24)\n",
    "plt.xlabel('Motor Neuron SegIDS', fontsize =18)\n",
    "plt.ylabel('Hair Plate Identity', fontsize =18)\n",
    "plt.yticks(fontsize = 16)\n",
    "plt.xticks(fontsize = 16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connectome of no soma neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reorder_idx_bysegfcn = utils.get_segment_fcn_order()\n",
    "# pre_wsoma_to_mn_df = pre_to_mn_df.loc[(All, True), :]\n",
    "fullfig2order_df = pre_to_mn_df.iloc[:,reorder_idx_bysegfcn]\n",
    "fullfig2order_df.shape\n",
    "# sim_mat = fullfig2order_df.to_numpy().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#reordered_mn_df = pre_to_mn_df.iloc[:,clustered_order]\n",
    "sim_mat = cosine_similarity(fullfig2order_df.to_numpy())\n",
    "ro_multidx = fullfig2order_df.columns\n",
    "\n",
    "# setting distance_threshold=0 ensures we compute the full tree.\n",
    "model = AgglomerativeClustering(distance_threshold=0, n_clusters=None).fit(sim_mat)\n",
    "\n",
    "# plot the top three levels of the dendrogram\n",
    "clustered_order = utils.plot_dendrogram(model, truncate_mode=\"level\", p=6000) # p truncate mode\n",
    "clustered_order = np.array(clustered_order).astype(int) # convert strins into integers\n",
    "print(clustered_order)\n",
    "reordered_pre_to_mn_df = fullfig2order_df.iloc[clustered_order,:]\n",
    "reordered_pre_to_mn_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_mat = cosine_similarity(reordered_pre_to_mn_df.to_numpy())\n",
    "\n",
    "# visualize matrix\n",
    "mn_labels = ro_multidx.get_level_values('muscle').to_list()\n",
    "mn_rank = ro_multidx.get_level_values('rank').to_list()\n",
    "mn_ids = ro_multidx.get_level_values('segID').to_list()\n",
    "idx = [str(i) for i in range(len(mn_ids))]\n",
    "sid = [str(i) for i in mn_ids]\n",
    "mn_rank = [str(i) for i in mn_rank]\n",
    "lbls = [i + '_' + j + '_' + k + '_' + l for i, j, k, l in zip(mn_labels, mn_rank, sid, idx,)]\n",
    "\n",
    "fig = plt.figure(1, figsize = [20,18])\n",
    "ax = sea.heatmap(sim_mat) #, xticklabels=mn_ids, yticklabels=lbls)\n",
    "# ax.xaxis.set_ticks_position('top')\n",
    "cbar = ax.collections[0].colorbar\n",
    "#ax.set_xticklabels(ax.get_xticklabels(),rotation = 90)\n",
    "\n",
    "# here set the labelsize by 20\n",
    "cbar.ax.tick_params(labelsize=20)\n",
    "cbar.set_label(label = 'cosine similarity', size=24)\n",
    "plt.xlabel('Premotor Neurons', fontsize =18)\n",
    "plt.ylabel('Premotor Neurons', fontsize =18)\n",
    "# plt.yticks(fontsize = 16)\n",
    "# plt.xticks(fontsize = 16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full connectome onto right and left sides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reorder_mn_mat = np.log10(reordered_pre_to_mn_df.to_numpy().transpose()+1)\n",
    "fig = plt.figure(1, figsize = [25,15])\n",
    "ax = sea.heatmap(reorder_mn_mat, yticklabels=lbls) #, cmap=parula_map\n",
    "cbar = ax.collections[0].colorbar\n",
    "# here set the labelsize by 20\n",
    "# cbar.ax.tick_params(labelsize=20)\n",
    "cbar.set_label(label = 'log 10 # of synapses', size=24)\n",
    "plt.xlabel('Motor Neuron SegIDS', fontsize =18)\n",
    "plt.ylabel('Hair Plate Identity', fontsize =18)\n",
    "plt.yticks(fontsize = 16)\n",
    "plt.xticks(fontsize = 16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find descending neurons\n",
    "Descending neurons are likely those with the most input and no somas.\n",
    "Try to make a table to not duplicate the effort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_topnosoma_df = pre_to_mn_df.loc[(All, False), :]\n",
    "\n",
    "# Find the total number of inputs\n",
    "s = pre_topnosoma_df.sum(axis=1)\n",
    "s\n",
    "pre_topnosoma_df.loc[:,'total'] = s\n",
    "pre_topnosoma_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_topnosoma_sorted_df= pre_topnosoma_df.sort_values(by='total',ascending=False)\n",
    "# pre_topnosoma_sorted_df.loc[pre_topnosoma_df.total>100,:] # This list is completed 4/25/22\n",
    "pre_topnosoma_sorted_df.loc[(pre_topnosoma_df.total>50) & (pre_topnosoma_df.total<=100),:] # This list is completed 4/25/22\n",
    "\n",
    "# order = totinputs.\n",
    "today = date.today()\n",
    "d1 = today.strftime(\"%Y%m%d\")\n",
    "#pre_topnosoma_sorted_df.loc[(pre_topnosoma_df.total>50) & (pre_topnosoma_df.total<=100),:].to_csv('./saved_dfs/nosoma_partners_' + d1 + '.csv')\n",
    "pre_topnosoma_sorted_df.loc[(pre_topnosoma_df.total>50)].to_csv('./saved_dfs/nosoma_partners_' + d1 + '.csv')\n",
    "print(pre_topnosoma_sorted_df.loc[(pre_topnosoma_df.total>50) & (pre_topnosoma_df.total<=100),:].shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find intersegmental neurons: have a soma, then distribution of synapses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T1 bounding box, from dacks lab\n",
    "x = [42542, 152542]\n",
    "y = [392291.4,532291.4]\n",
    "z = [37065,162065]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Produce lists of neurons to edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output the entire list. \n",
    "# Have three columns: \n",
    "# 1)the seg id of the premotor neuron, \n",
    "# 2) the segid of the motor neuron receiving the most input, \n",
    "# 3) and the number of synapses\n",
    "All = slice(None)\n",
    "\n",
    "mn_segids = reordered_pre_to_mn_df.columns.get_level_values('segID').to_list()\n",
    "mn_labels = reordered_pre_to_mn_df.columns.get_level_values('muscle').to_list()\n",
    "mn_rank = reordered_pre_to_mn_df.columns.get_level_values('rank').to_list()\n",
    "mn_rank = [str(i) for i in mn_rank]\n",
    "mn_lbls = [i + '_' + j for i, j in zip(mn_labels, mn_rank)]\n",
    "\n",
    "# create a square dataframe of 1s\n",
    "dfdata = np.zeros([reordered_pre_to_mn_df.shape[0],3],dtype=np.uint64)\n",
    "temp_df = pd.DataFrame(dfdata,index=reordered_pre_to_mn_df.index, columns=['top_MN_partner','label','synapse_cnt'])\n",
    "                  \n",
    "for segid1, row in reordered_pre_to_mn_df.iterrows():\n",
    "    rownp = row.to_numpy()\n",
    "    idx = rownp.argmax()\n",
    "    temp_df.loc[segid1,'top_MN_partner'] = mn_segids[idx]\n",
    "    temp_df.loc[segid1,'label'] = mn_lbls[idx]\n",
    "    temp_df.loc[segid1,'synapse_cnt'] = rownp[idx]\n",
    "    \n",
    "\n",
    "today = date.today()\n",
    "d1 = today.strftime(\"%Y%m%d\")\n",
    "temp_df.to_csv('./saved_dfs/sortedPresyapticNeuronsAndMajorPartner_' + d1 + '.csv')\n",
    "print(temp_df.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output sources that provide input to a single motor neuron\n",
    "# Have three columns: \n",
    "# 1)the seg id of the premotor neuron, \n",
    "# 2) the segid of the motor neuron receiving the most input, \n",
    "# 3) and the number of synapses\n",
    "All = slice(None)\n",
    "\n",
    "mn_segids = reordered_pre_to_mn_df.columns.get_level_values('segID').to_list()\n",
    "mn_labels = reordered_pre_to_mn_df.columns.get_level_values('muscle').to_list()\n",
    "mn_rank = reordered_pre_to_mn_df.columns.get_level_values('rank').to_list()\n",
    "mn_rank = [str(i) for i in mn_rank]\n",
    "mn_lbls = [i + '_' + j for i, j in zip(mn_labels, mn_rank)]\n",
    "\n",
    "# create a square dataframe of 1s\n",
    "dfdata = np.zeros([reordered_pre_to_mn_df.shape[0],3],dtype=np.uint64)\n",
    "singletarget_df = pd.DataFrame(dfdata,index=reordered_pre_to_mn_df.index, columns=['top_MN_partner','label','synapse_cnt'])\n",
    "singletarget_nosoma_df = pd.DataFrame(dfdata,index=reordered_pre_to_mn_df.index, columns=['top_MN_partner','label','synapse_cnt'])\n",
    "cnt = 0\n",
    "nosomacnt = 0\n",
    "\n",
    "for segid1, row in reordered_pre_to_mn_df.iterrows():\n",
    "    rownp = row.to_numpy()\n",
    "    if np.sum(rownp>0) > 1:\n",
    "        cnt = cnt+1;\n",
    "        continue\n",
    "    elif segid1 not in soma_table.pt_root_id.to_list():\n",
    "        nosomacnt = nosomacnt+1\n",
    "        idx = rownp.argmax()\n",
    "        singletarget_nosoma_df.loc[segid1,'top_MN_partner'] = mn_segids[idx]\n",
    "        singletarget_nosoma_df.loc[segid1,'label'] = mn_lbls[idx]\n",
    "        singletarget_nosoma_df.loc[segid1,'synapse_cnt'] = rownp[idx]\n",
    "        \n",
    "    singletarget_df.loc[segid1,'top_MN_partner'] = mn_segids[idx]\n",
    "    singletarget_df.loc[segid1,'label'] = mn_lbls[idx]\n",
    "    singletarget_df.loc[segid1,'synapse_cnt'] = rownp[idx]\n",
    "    \n",
    "today = date.today()\n",
    "d1 = today.strftime(\"%Y%m%d\")\n",
    "\n",
    "singletarget_nosoma_df = singletarget_nosoma_df.loc[singletarget_nosoma_df['synapse_cnt']>0,All]\n",
    "singletarget_df = singletarget_df.loc[singletarget_df['synapse_cnt']>0,All]\n",
    "\n",
    "singletarget_nosoma_df.to_csv('./saved_dfs/sortedmninputs_singleinput_nosoma_' + d1 +'.csv')\n",
    "singletarget_df.to_csv('./saved_dfs/sortedmninputs_singleinput_' + d1 +'.csv')\n",
    "\n",
    "singletarget_df.head()\n",
    "print(singletarget_nosoma_df.shape)\n",
    "print(singletarget_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output list of inputs to FETi and SETi\n",
    "Tidf = reordered_pre_to_mn_df.loc[:,(All,All,All,All,All,['feti','seti'],All)]\n",
    "# reordered_pre_to_mn_df.columns\n",
    "maxidx = np.argsort(np.max(Tidf.to_numpy(),axis=1))\n",
    "print(maxidx.shape)\n",
    "Tidf_ordrd = Tidf.iloc[np.flipud(maxidx),All]\n",
    "today = date.today()\n",
    "d1 = today.strftime(\"%Y%m%d\")\n",
    "Tidf_ordrd.to_csv('./saved_dfs/sortedmninputs_feti_seti' + d1 +'.csv')\n",
    "#Tidf_ordrd_no0 = Tidf_ordrd.loc[Tidf_ordrd['feti']>0 or Tidf_ordrd['seti'],All]\n",
    "Tidf_ordrd.head()\n",
    "# dfdata = np.zeros([reordered_pre_to_mn_df.shape[0],3],dtype=np.uint64)\n",
    "# singletarget_df = pd.DataFrame(dfdata,index=reordered_pre_to_mn_df.index, columns=['top_MN_partner','label','synapse_cnt'])\n",
    "# singletarget_nosoma_df = pd.DataFrame(dfdata,index=reordered_pre_to_mn_df.index, columns=['top_MN_partner','label','synapse_cnt'])\n",
    "# cnt = 0\n",
    "# nosomacnt = 0\n",
    "\n",
    "# for segid1, row in reordered_pre_to_mn_df.iterrows():\n",
    "#     rownp = row.to_numpy()\n",
    "#     if np.sum(rownp>0) > 1:\n",
    "#         cnt = cnt+1;\n",
    "#         continue\n",
    "#     elif segid1 not in soma_table.pt_root_id.to_list():\n",
    "#         nosomacnt = nosomacnt+1\n",
    "#         idx = rownp.argmax()\n",
    "#         singletarget_nosoma_df.loc[segid1,'top_MN_partner'] = mn_segids[idx]\n",
    "#         singletarget_nosoma_df.loc[segid1,'label'] = mn_lbls[idx]\n",
    "#         singletarget_nosoma_df.loc[segid1,'synapse_cnt'] = rownp[idx]\n",
    "        \n",
    "#     singletarget_df.loc[segid1,'top_MN_partner'] = mn_segids[idx]\n",
    "#     singletarget_df.loc[segid1,'label'] = mn_lbls[idx]\n",
    "#     singletarget_df.loc[segid1,'synapse_cnt'] = rownp[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO:\n",
    "- Analyse the Left R neurons\n",
    "- What neurons are contributing to the similarity across segments?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('fanc310')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "d31c769b0a61eed01ed31a455ec85601800f9afe81f6f1c3ac0415bd98de4e59"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
