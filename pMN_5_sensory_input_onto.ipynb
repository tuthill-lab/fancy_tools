{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import utils\n",
    "import connectome_create\n",
    "# viz_method = one of ['itkwidgets', 'vtk']\n",
    "viz_method = 'vtk'\n",
    "\n",
    "# import some of our favorite packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import warnings\n",
    "\n",
    "%matplotlib inline\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "# import nglui.statebuilder as ngstbld\n",
    "\n",
    "# # this is the EM specific package for querying the EM data\n",
    "from caveclient import CAVEclient\n",
    "\n",
    "\n",
    "# from meshparty import trimesh_io, trimesh_vtk\n",
    "# from meshparty import skeletonize, skeleton_io, skeleton\n",
    "import cloudvolume\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load Premotor table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pre_to_df = connectome_create.load_pre_to_df(ext='ordered_no_frags')\n",
    "pre_to_df.loc['motor'].index.to_frame().set_index('preferred_pool').to_csv('./dfs_saved/mn_to_pool_match.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_to_mn_df = connectome_create.load_pre_to_mn_df(ext='matched_typed_with_nt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool_keys = [\n",
    "        'thorax_swing',\n",
    "        'thorax_stance',\n",
    "        'trochanter_extension',\n",
    "        'trochanter_flexion',\n",
    "        'femur_reductor',\n",
    "        'tibia_extensor',\n",
    "        'main_tibia_flexor',\n",
    "        # 'auxiliary_tibia_flexor_A',\n",
    "        'auxiliary_tibia_flexor_B',\n",
    "        'auxiliary_tibia_flexor_E',\n",
    "        'ltm',\n",
    "        'tarsus_depressor_med_venU',\n",
    "        'tarsus_depressor_noid',\n",
    "        ]\n",
    "\n",
    "# input: ['cell_class', 'preferred_pool', 'NT', 'classification_system', 'cell_type', 'segID']\n",
    "# output: ['cell_class', 'preferred_pool', 'NT', 'classification_system', 'cell_type', 'post_pt_root_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot sensory neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "All = slice(None)\n",
    "input_tup = ('sensory',All,All,All,All,All)\n",
    "output_tup = ('motor',All,All,All,All,All)\n",
    "\n",
    "pre_df_slice = pre_to_df.loc[output_tup,input_tup]\n",
    "\n",
    "%config InlineBackend.figure_formats = ['png']\n",
    "%matplotlib inline\n",
    "\n",
    "cmap = utils.white_dense()\n",
    "\n",
    "fig = plt.figure(1, figsize = [8,16])\n",
    "ax = sns.heatmap(np.log10(pre_df_slice.T.to_numpy()+1), cmap=cmap)\n",
    "cbar = ax.collections[0].colorbar\n",
    "# here set the labelsize by 20\n",
    "# cbar.ax.tick_params(labelsize=20)\n",
    "cbar.set_label(label = 'log 10 # of synapses', size=24)\n",
    "plt.xlabel('Motor Neurons', fontsize =18)\n",
    "plt.ylabel('All to motor', fontsize =18)\n",
    "plt.yticks(fontsize = 16)\n",
    "plt.xticks(fontsize = 16)\n",
    "plt.show()\n",
    "\n",
    "# Not enough here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_formats = ['png']\n",
    "%matplotlib inline\n",
    "\n",
    "cmap = utils.white_dense()\n",
    "def conn_heat_map(df,xticks,yticks,figsz=[16,16],savefig=False,figfilename=None,cmap=cmap):\n",
    "    fig = plt.figure(1, figsize = figsz)\n",
    "    ax = sns.heatmap(np.log10(df.T.to_numpy()+1), xticklabels=xticks, yticklabels=yticks, cmap=cmap)\n",
    "    cbar = ax.collections[0].colorbar\n",
    "    # here set the labelsize by 20\n",
    "    # cbar.ax.tick_params(labelsize=20)\n",
    "    cbar.set_label(label = 'log 10 # of synapses', size=24)\n",
    "    plt.xlabel('Onto Output neurons', fontsize =18)\n",
    "    plt.ylabel('From input neurons', fontsize =18)\n",
    "    plt.yticks(fontsize = 16)\n",
    "    plt.xticks(fontsize = 16)\n",
    "    plt.show()\n",
    "    if savefig:\n",
    "        if figfilename is None:\n",
    "            figfilename = 'flexor_pool_temp_' + (np.random.randint(10000,99999,size=None)).astype(str)\n",
    "        fig.savefig('./figpanels/' + figfilename + '.svg',format='svg')\n",
    "\n",
    "def lin_heat_map(df,xticks,yticks,figsz=[16,16],savefig=False,figfilename=None,cmap=cmap):\n",
    "    fig = plt.figure(1, figsize = figsz)\n",
    "    ax = sns.heatmap(df.T.to_numpy(), xticklabels=xticks, yticklabels=yticks, cmap=cmap)\n",
    "    cbar = ax.collections[0].colorbar\n",
    "    # here set the labelsize by 20\n",
    "    # cbar.ax.tick_params(labelsize=20)\n",
    "    cbar.set_label(label = 'linear', size=24)\n",
    "    plt.xlabel('Onto Output neurons', fontsize =18)\n",
    "    plt.ylabel('From input neurons', fontsize =18)\n",
    "    plt.yticks(fontsize = 16)\n",
    "    plt.xticks(fontsize = 16)\n",
    "    plt.show()\n",
    "    if savefig:\n",
    "        if figfilename is None:\n",
    "            figfilename = 'flexor_pool_temp_' + (np.random.randint(10000,99999,size=None)).astype(str)\n",
    "        fig.savefig('./figpanels/' + figfilename + '.svg',format='svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use the motory-ness routine to look at sensory neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cum_motor_premotor(pre_df,c_tup):\n",
    "    ct_df = pre_df.loc[:,c_tup] # a more generalized version of the above\n",
    "\n",
    "    # pd.Series\n",
    "\n",
    "    # pd.DataFrame of fractional inputs\n",
    "    cell_classes = ct_df.index.get_level_values('cell_class').unique()\n",
    "    frac_df = pd.DataFrame(index=cell_classes,columns=ct_df.columns)\n",
    "    for key in cell_classes:\n",
    "        frac_df.loc[key,:] = ct_df.loc[key,:].sum(axis=0)        \n",
    "\n",
    "    ct_to_all    = ct_df.loc[All,:].sum(axis=0)                         # calculate the total\n",
    "    x = [i for i in range(len(ct_df.loc['motor',:].sum(axis=0)))]   \n",
    "    frac_df.loc['x',:] = x                                              # this x is the original order of the cell_class\n",
    "    frac_df.loc['total',:] = ct_to_all\n",
    "\n",
    "    otherpre = ['descending', \n",
    "                'sensory', \n",
    "                'ascending', \n",
    "                'intersegmental',]\n",
    "                \n",
    "    frac_df.loc['other_pre',:] = frac_df.loc[otherpre,:].sum(axis=0)\n",
    "\n",
    "\n",
    "    otherlist = ['non_t1_motor', \n",
    "                'descending_post', \n",
    "                'sensory_post',\n",
    "                'ascending_post', \n",
    "                'neurmodulatory_ascending_neuron',\n",
    "                'vnc_non_premotor']\n",
    "    \n",
    "    frac_df.loc['other',:] = frac_df.loc[otherlist,:].sum(axis=0)\n",
    "    frac_df.loc['other',:] = frac_df.loc['other',:]/ct_to_all \n",
    "    frac_df = frac_df.drop(otherlist,axis=0)\n",
    "    \n",
    "    frac_df = frac_df.sort_values(['other'],axis=1,ascending=True)    # sort according to how other fraction\n",
    "    sorted_total=frac_df.loc['total',:].to_numpy()                      # keep the sorted total \n",
    "    frac_df = frac_df.drop('total',axis=0)                             # drop the total row\n",
    "\n",
    "    frac_df.loc['cum_motor',:] = frac_df.loc['motor',:].cumsum()\n",
    "    frac_df.loc['cum_motor_frac',:] = frac_df.loc['cum_motor',:]/frac_df.loc['motor',:].sum()\n",
    "\n",
    "    frac_df.loc['cum_local',:]          = frac_df.loc['local',:].cumsum()\n",
    "    frac_df.loc['cum_descending',:]     = frac_df.loc['descending',:].cumsum()\n",
    "    frac_df.loc['cum_sensory',:]        = frac_df.loc['sensory',:].cumsum()\n",
    "    frac_df.loc['cum_intersegmental',:] = frac_df.loc['intersegmental',:].cumsum()\n",
    "    frac_df.loc['cum_other_pre',:] = frac_df.loc['other_pre',:].cumsum()\n",
    "    \n",
    "\n",
    "    # clean up a little\n",
    "    frac_df.loc['cum_motor',frac_df.loc['cum_motor',:]==0] = np.nan\n",
    "    frac_df.loc['cum_local',frac_df.loc['cum_local',:]==0] = np.nan\n",
    "    frac_df.loc['cum_other_pre',frac_df.loc['cum_other_pre',:]==0] = np.nan\n",
    "\n",
    "    # frac_df.loc['cum_motor_over_pre',:] = frac_df.loc['cum_motor',:]/frac_df.loc['cum_local',:]\n",
    "    frac_df.loc['cum_local_over_motor',:] = frac_df.loc['cum_local',:]/frac_df.loc['cum_motor',:]\n",
    "    frac_df.loc['cum_inter_over_motor',:] = frac_df.loc['cum_intersegmental',:]/frac_df.loc['cum_motor',:]\n",
    "    frac_df.loc['cum_other_over_motor',:] = frac_df.loc['cum_other_pre',:]/frac_df.loc['cum_motor',:]\n",
    "\n",
    "    # frac_df.loc['cum_local_over_motor',frac_df.loc['cum_local_over_motor',:]>10] = np.nan\n",
    "    # frac_df.loc['cum_other_over_motor',frac_df.loc['cum_other_over_motor',:]>10] = np.nan\n",
    "\n",
    "    return frac_df, sorted_total\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at sensory input on to local neurons compared to mns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensory = pre_to_df.loc[:,('sensory',All,All,All,All)]\n",
    "frac_df, sorted_total = get_cum_motor_premotor(pre_to_df,('sensory',All,All,All,All))\n",
    "sens_motor_df = frac_df.sort_values(['motor'],axis=1,ascending=False)\n",
    "\n",
    "# find the indices of the top 5 sensory neurons in frac_df\n",
    "idx = []\n",
    "sens_idx = idx\n",
    "for rtid in sens_motor_df.columns.get_level_values('segID').to_list()[0:9]:\n",
    "    print(rtid)\n",
    "    idx = idx+[frac_df.columns.get_locs((All,All,All,All,All,rtid))[0]]\n",
    "    sens_idx = sens_idx+[sensory.columns.get_locs((All,All,All,All,All,rtid))[0]]\n",
    "\n",
    "print(idx)\n",
    "print(sens_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motory_cutoff_idx = np.array(idx).max()\n",
    "motor_cutoff_tup = frac_df.columns[motory_cutoff_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2, figsize=(10,8),gridspec_kw={'width_ratios': [2, 1,]})\n",
    "xdim = pre_to_df.loc[:,('sensory',All,All,All,All)].shape[1]\n",
    "x = [i for i in range(len(sorted_total))]\n",
    "ax[0,0].plot(x,frac_df.loc['cum_local_over_motor',:],color=\"#7D688E\",label='local')\n",
    "ax[0,0].plot(x,frac_df.loc['cum_inter_over_motor',:],color=\"#7D688E\",label='local')\n",
    "ax[0,0].set_xlim(0,xdim)\n",
    "ax[0,0].set_ylim(0,6)\n",
    "ax[1,0].plot(x,frac_df.loc['cum_motor',:],color='#910951')\n",
    "ax[1,0].set_xlim(0,xdim)\n",
    "ax[1,0].set_ylim(0,frac_df.loc['cum_motor',:].max()*1.05)\n",
    "\n",
    "ax[0,1].plot(frac_df.loc['motor'],frac_df.loc['local']/frac_df.loc['motor'],color='#cccccc',marker='.',ls='none')\n",
    "ax[0,0].plot(np.array([motory_cutoff_idx,motory_cutoff_idx]),np.array([0,6]),color='#cccccc')\n",
    "\n",
    "ax[1,1].plot(frac_df.loc['motor'],frac_df.loc['local']/frac_df.loc['motor'],color='#cccccc',marker='.',ls='none')\n",
    "\n",
    "for i in idx:\n",
    "    ax[1,0].plot(x[i],frac_df.loc['cum_motor'].iloc[i],color='#910951',marker='o')\n",
    "    ax[0,1].plot(frac_df.loc['motor'].iloc[i],frac_df.loc['local'].iloc[i]/frac_df.loc['motor'].iloc[i],color='#910951',marker='o')\n",
    "    ax[1,1].plot(frac_df.loc['motor'].iloc[i],frac_df.loc['local'].iloc[i]/frac_df.loc['motor'].iloc[i],color='#910951',marker='o')\n",
    "\n",
    "# ax[1,1].set_xlim(0,)\n",
    "ax[1,1].set_ylim(0,6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input to common local circuitry\n",
    "Consider those desc neurons that tend to target T1 stuff, ie. less onto other stuff than the 5 outliers. What is the ratio of preferred pool input to other pools?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_first_string_in_list(in_list):\n",
    "    out_list = []\n",
    "    key = None\n",
    "    for s in in_list:\n",
    "        if key is None:\n",
    "            key = s\n",
    "            out_list = out_list + [key]\n",
    "            continue\n",
    "        elif s==key:\n",
    "            out_list = out_list + ['']\n",
    "        else:\n",
    "            key = s\n",
    "            out_list = out_list + [s]\n",
    "    return out_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motor_pool_df = sensory.loc['motor']\n",
    "motor_pool_df = motor_pool_df.groupby(by='preferred_pool',axis=0).sum()\n",
    "motor_pool_df = motor_pool_df.loc[pool_keys,:]\n",
    "\n",
    "motor_targets_df = sensory.loc['motor']\n",
    "motor_targets_df = motor_targets_df.groupby(by='preferred_pool',axis=0).sum()\n",
    "motor_targets_df = motor_targets_df/motor_targets_df.sum(axis=0)\n",
    "motor_targets_df = motor_targets_df.loc[pool_keys,:]\n",
    "motor_targets_df.loc['pref_pool_input'] = np.nan\n",
    "for tup in motor_targets_df.columns.to_list():\n",
    "    motor_targets_df.loc['pref_pool_input',tup] = motor_targets_df.loc[tup[1],tup]\n",
    "\n",
    "local_targets_df = sensory.loc['local']\n",
    "local_targets_df = local_targets_df.groupby(by='preferred_pool',axis=0).sum()\n",
    "local_targets_df = local_targets_df/local_targets_df.sum(axis=0)\n",
    "local_targets_df = local_targets_df.loc[pool_keys,:]\n",
    "\n",
    "local_targets_df.loc['pref_pool_input'] = np.nan\n",
    "for tup in local_targets_df.columns.to_list():\n",
    "    local_targets_df.loc['pref_pool_input',tup] = local_targets_df.loc[tup[1],tup]\n",
    "\n",
    "\n",
    "# yticklabels = [x + '_' + str(y) for x,y in zip(local_targets_df.columns.get_level_values('preferred_pool'),local_targets_df.columns.get_level_values('segID'))]\n",
    "yticklabels = keep_first_string_in_list(local_targets_df.columns.get_level_values('preferred_pool').to_list())\n",
    "\n",
    "conn_heat_map(df=motor_pool_df, xticks=local_targets_df.index.get_level_values('preferred_pool'),yticks=yticklabels,figsz=[4,16])\n",
    "lin_heat_map(df=motor_targets_df, xticks=local_targets_df.index.get_level_values('preferred_pool'),yticks=yticklabels,figsz=[4,16])\n",
    "lin_heat_map(df=local_targets_df, xticks=local_targets_df.index.get_level_values('preferred_pool'),yticks=yticklabels,figsz=[4,16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensory.max().max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pool motoryness vs. pool pre-motory-ness?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10,8)) #,gridspec_kw={'width_ratios': [2, 1,],'height_ratios': [2,.2]})\n",
    "ax.plot(motor_targets_df.loc['pref_pool_input'],local_targets_df.loc['pref_pool_input'],color=\"#cccccc\",label='local',marker='.',ls='none')\n",
    "\n",
    "for i in sens_idx:\n",
    "    ax.plot(motor_targets_df.loc['pref_pool_input'].iloc[i],local_targets_df.loc['pref_pool_input'].iloc[i],color=\"#910951\",label='local',marker='o',ls='none')\n",
    "\n",
    "ax.set_xlabel('Pool preference strength - MNs')\n",
    "ax.set_ylabel('Pool preference strength - local')\n",
    "print(sensory.loc['motor',((motor_targets_df.loc['pref_pool_input']==1) & (local_targets_df.loc['pref_pool_input']==1))].sum(axis=0))\n",
    "\n",
    "pd.concat([motor_targets_df.loc[['pref_pool_input']],local_targets_df.loc[['pref_pool_input']]],axis=0).T.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensory neurons vs. HL?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create lookuptable\n",
    "cell_types = pre_to_mn_df.index.get_level_values('cell_type').unique().to_numpy()\n",
    "nt_table = pd.read_csv('./annotations_hl/LacinHLTable.csv')\n",
    "import re\n",
    "pattern = re.compile(\"R[0-9]\")\n",
    "\n",
    "hl_lut = {'cell_type':cell_types,'hemilineage':cell_types}\n",
    "hl_lut = pd.DataFrame(data=hl_lut)\n",
    "\n",
    "for idx,r in hl_lut.iterrows():\n",
    "    try:\n",
    "        if np.isnan(r.hemilineage):\n",
    "            continue\n",
    "    except TypeError:\n",
    "        pass\n",
    "    hl = r.hemilineage\n",
    "\n",
    "    if hl[0:2]=='RD':\n",
    "        hl = '24B'\n",
    "        # print('string was RD, now {}'.format(hl))\n",
    "\n",
    "    if pattern.match(hl) or hl=='RVD' or hl=='Rcore_':\n",
    "        # print('string was {}, now 8A'.format(hl))\n",
    "        hl = '8A'\n",
    "\n",
    "    if not hl.isalnum():\n",
    "        hl = hl[0:-1]\n",
    "        # print(hl)\n",
    "    \n",
    "    if not hl.isalnum():\n",
    "        hl=hl[0:hl.find('_')]\n",
    "        # print(hl)\n",
    "\n",
    "    if hl == '9Ac':\n",
    "        hl='9A'\n",
    "        # print(hl)\n",
    "\n",
    "    hl_lut.loc[idx,'hemilineage'] = hl\n",
    "\n",
    "# merge with neurotransmitter table to get a lookuptable\n",
    "hl_lut = hl_lut.merge(nt_table,how='outer',left_on='hemilineage',right_on='HL')\n",
    "hl_lut = hl_lut.loc[~hl_lut.hemilineage.isna(),:]\n",
    "\n",
    "hl_lut_reduced = hl_lut[['cell_type','NT','hemilineage']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simplify the hemilineages\n",
    "local_targets_df = sensory.loc['local']\n",
    "\n",
    "# just operate on the index, where the nt will be\n",
    "pmn_index_df = local_targets_df.index.to_frame().reset_index(drop=True)\n",
    "\n",
    "# join the index on cell_type, with NT\n",
    "pmn_index_df = pmn_index_df.join(hl_lut_reduced.set_index('cell_type'),how='left',on='cell_type',lsuffix='_x',rsuffix='_y')\n",
    "\n",
    "# reorder the matrix\n",
    "pmn_index_df = pmn_index_df[['preferred_pool','NT_x','classification_system','cell_type','hemilineage','post_pt_root_id']]\n",
    "pmn_index_df.hemilineage.value_counts()\n",
    "\n",
    "local_targets_df.index = pd.MultiIndex.from_frame(pmn_index_df)\n",
    "local_targets_df = local_targets_df.groupby(by='hemilineage',axis=0).sum()\n",
    "\n",
    "hl_preference_df = local_targets_df.copy()\n",
    "# local_targets_df.loc['pref_HL'] = np.nan\n",
    "\n",
    "for tup in local_targets_df.columns.to_list():\n",
    "    # print(tup)\n",
    "    hl_preference_df.loc[:,tup] = local_targets_df.loc[:,tup]/local_targets_df.loc[:,tup].sum(axis=0)\n",
    "    # local_targets_df.loc['pref_HL',tup] = local_targets_df.loc[:,tup].max(axis=0)/local_targets_df.loc[:,tup].sum(axis=0)\n",
    "\n",
    "yticklabels = keep_first_string_in_list(local_targets_df.columns.get_level_values('preferred_pool').to_list())\n",
    "\n",
    "conn_heat_map(df=local_targets_df, xticks=local_targets_df.index.get_level_values('hemilineage'),yticks=yticklabels,figsz=[10,16])\n",
    "lin_heat_map(df=hl_preference_df, xticks=local_targets_df.index.get_level_values('hemilineage'),yticks=yticklabels,figsz=[10,16])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensory vs NT?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simplify the hemilineages\n",
    "local_targets_df = sensory.loc['local']\n",
    "local_targets_df = local_targets_df.groupby(by='NT',axis=0).sum()\n",
    "\n",
    "nt_preference_df = local_targets_df.copy()\n",
    "# local_targets_df.loc['pref_HL'] = np.nan\n",
    "\n",
    "for tup in local_targets_df.columns.to_list():\n",
    "    # print(tup)\n",
    "    nt_preference_df.loc[:,tup] = local_targets_df.loc[:,tup]/local_targets_df.loc[:,tup].sum(axis=0)\n",
    "    # local_targets_df.loc['pref_HL',tup] = local_targets_df.loc[:,tup].max(axis=0)/local_targets_df.loc[:,tup].sum(axis=0)\n",
    "\n",
    "yticklabels = keep_first_string_in_list(local_targets_df.columns.get_level_values('preferred_pool').to_list())\n",
    "\n",
    "conn_heat_map(df=local_targets_df, xticks=local_targets_df.index.get_level_values('NT'),yticks=yticklabels,figsz=[1,16])\n",
    "lin_heat_map(df=nt_preference_df, xticks=local_targets_df.index.get_level_values('NT'),yticks=yticklabels,figsz=[1,16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nt_preference_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10,8)) #,gridspec_kw={'width_ratios': [2, 1,],'height_ratios': [2,.2]})\n",
    "ax.plot(local_targets_df.loc['Ach'],local_targets_df.loc['Glu'],color=\"#000000\",label='local',marker='.',ls='none')\n",
    "ax.plot([0, local_targets_df.loc['Ach'].max()],[0, local_targets_df.loc['Ach'].max()],color='#cccccc' )\n",
    "ax.set_aspect('equal', 'box')\n",
    "ax.set_xlabel('Ach connections')\n",
    "ax.set_ylabel('Glu connections')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in desc_idx:\n",
    "    ax.plot(motor_targets_df.loc['pref_pool_input'].iloc[i],local_targets_df.loc['pref_pool_input'].iloc[i],color=\"#910951\",label='local',marker='o',ls='none')\n",
    "\n",
    "ax.set_xlabel('Pool preference strength - MNs')\n",
    "ax.set_ylabel('Pool preference strength - local')\n",
    "print(descending.loc['motor',((motor_targets_df.loc['pref_pool_input']==1) & (local_targets_df.loc['pref_pool_input']==1))].sum(axis=0))\n",
    "\n",
    "pd.concat([motor_targets_df.loc[['pref_pool_input']],local_targets_df.loc[['pref_pool_input']]],axis=0).T.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Take a look at the biggest descending neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "All = slice(None)\n",
    "input_tup = ('sensory',All,All,All,All,sens_motor_df.columns.get_level_values('segID').to_list()[0:9])\n",
    "output_tup = ('motor',All,All,All,All,All)\n",
    "\n",
    "big_desc_df = pre_to_df.loc[output_tup,input_tup]\n",
    "mnpoollabel = big_desc_df.index.get_level_values('preferred_pool')\n",
    "yticklabels = [x + '_' + str(y) for x,y in zip(big_desc_df.columns.get_level_values('preferred_pool'),big_desc_df.columns.get_level_values('segID'))]\n",
    "conn_heat_map(df=big_desc_df, xticks=mnpoollabel,yticks=yticklabels,figsz=[16,4])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many intersegmental neurons? # ~350\n",
    "# segID\tmotor\thas_soma\tsensory\t neck\tlocal\t\n",
    "\n",
    "def get_motory_fraction(pre_df,c_tup,compress_other_classes=False):\n",
    "    ct_df = pre_df.loc[:,c_tup] # a more generalized version of the above\n",
    "\n",
    "    # pd.Series\n",
    "\n",
    "    # pd.DataFrame of fractional inputs\n",
    "    cell_classes = ct_df.index.get_level_values('cell_class').unique()\n",
    "    frac_df = pd.DataFrame(index=cell_classes,columns=ct_df.columns)\n",
    "\n",
    "    for key in cell_classes:\n",
    "        frac_df.loc[key,:] = ct_df.loc[key,:].sum(axis=0)\n",
    "\n",
    "    \n",
    "    if compress_other_classes:\n",
    "        otherlist = ['non_t1_motor', \n",
    "                    'descending_post', \n",
    "                    'sensory_post',\n",
    "                    'ascending_post', \n",
    "                    'neurmodulatory_ascending_neuron',\n",
    "                    'vnc_non_premotor']\n",
    "        frac_df.loc['other',:] = frac_df.loc[otherlist,:].sum(axis=0)\n",
    "        \n",
    "    ct_to_all    = ct_df.loc[All,:].sum(axis=0)                         # calculate the total\n",
    "    frac_df = frac_df/ct_to_all                                         # divide by the total\n",
    "    x = [i for i in range(len(ct_df.loc['motor',:].sum(axis=0)))]   \n",
    "    frac_df.loc['x',:] = x                                              # this x is the original order of the cell_class\n",
    "    frac_df.loc['total',:] = ct_to_all\n",
    "    frac_df = frac_df.sort_values(['motor'],axis=1,ascending=False)    # sort according to how t1 motory\n",
    "\n",
    "    sorted_total=frac_df.loc['total',:].to_numpy()                      # keep the sorted total \n",
    "    frac_df  = frac_df.drop('total',axis=0)                             # drop the total row\n",
    "    \n",
    "    if compress_other_classes:\n",
    "        frac_df = frac_df.drop(otherlist,axis=0)\n",
    "        frac_df = frac_df.sort_values(['other'],axis=1,ascending=False)    # sort according to how t1 motory\n",
    "    \n",
    "    return frac_df, sorted_total                                       \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First get the motoryness of the Tibia extensor, flexor pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first sort by motoryness\n",
    "input_tup = ('local',['tibia_extensor','main_tibia_flexor'],All,All,All,All,All)\n",
    "frac_df,sorted_total = get_motory_fraction(pre_to_df,input_tup,compress_other_classes=False)\n",
    "\n",
    "pre_onto_ti_ext_flex_df = pre_to_df.loc[:,input_tup]\n",
    "pre_onto_ti_ext_flex_df = pre_onto_ti_ext_flex_df.loc[:,frac_df.columns]\n",
    "pre_onto_ti_ext_flex_df\n",
    "\n",
    "# # locs, labels = plt.xticks(ticks=x, labels=lbls, rotation=90)\n",
    "          #'motor', 'nont1',    'desc',     'sens',     'ascend',   'local',    'intr',     'vnc',      'fragments'\n",
    "colors = [\"#910951\",\"#CC4893\",  \"#79D0F7\",  \"#93E5B6\",  \"#6084CC\",  \"#7D688E\",  \"#CC9FCC\",  '#5C085E',   '#cccccc']\n",
    "cmap = sns.set_palette(sns.color_palette(colors))\n",
    "x = [i for i in range(len(sorted_total))]\n",
    "ax = frac_df.T.plot(x='x',kind='bar', stacked=True, legend = True,width=1,cmap=cmap,figsize=(16,40)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show the Motor neurons first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_tup = ('local',['tibia_extensor','main_tibia_flexor'],All,All,All,All,All)\n",
    "output_tup = ('motor',['tibia_extensor','main_tibia_flexor'],All,All,All,All,All)\n",
    "\n",
    "pre_onto_ti_ext_flex_df = pre_onto_ti_ext_flex_df.loc[output_tup,:]\n",
    "# weird neurons\n",
    "print('no NT: {}'.format(pre_onto_ti_ext_flex_df.loc[:,~pre_onto_ti_ext_flex_df.columns.get_level_values('NT').isin(['Ach','GABA','Glu'])].columns.get_level_values('segID').to_list()))\n",
    "# Get rid of the last two pMNs\n",
    "pre_onto_ti_ext_flex_df = pre_onto_ti_ext_flex_df.loc[:,pre_onto_ti_ext_flex_df.columns.get_level_values('NT').isin(['Ach','GABA','Glu'])]\n",
    "\n",
    "# xticklabels = pre_onto_ti_ext_flex_df.index.get_level_values('preferred_pool')\n",
    "# yticklabels = pre_df_ti_ext_flex.columns.get_level_values('NT')\n",
    "\n",
    "# conn_heat_map(df=pre_df_ti_ext_flex, xticks=xticklabels,yticks=yticklabels,figsz=[4,16])\n",
    "\n",
    "# order by NT\n",
    "cols_ntsorted,c_array = pre_onto_ti_ext_flex_df.columns.sortlevel(level='NT',ascending=True,sort_remaining=False)\n",
    "mn_nt_sorted = pre_onto_ti_ext_flex_df.loc[:,cols_ntsorted]\n",
    "\n",
    "# order by pool\n",
    "cols_ntsorted,c_array = mn_nt_sorted.columns.sortlevel(level='preferred_pool',ascending=True,sort_remaining=False)\n",
    "output_tup = ('local',['tibia_extensor','main_tibia_flexor'],All,All,All,All,All)\n",
    "mn_nt_pool_sorted = mn_nt_sorted.loc[:,output_tup]\n",
    "\n",
    "mnpoollabel = mn_nt_pool_sorted.index.get_level_values('preferred_pool')\n",
    "yticklabels = mn_nt_pool_sorted.columns.get_level_values('NT')\n",
    "\n",
    "conn_heat_map(df=mn_nt_pool_sorted, xticks=mnpoollabel,yticks=yticklabels,figsz=[4,16])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Order local neurons by NT, and pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_tup = ('local',['tibia_extensor','main_tibia_flexor'],All,All,All,All)\n",
    "output_tup = ('local',['tibia_extensor','main_tibia_flexor'],All,All,All,All,All)\n",
    "\n",
    "pre_onto_ti_ext_flex_df = pre_onto_ti_ext_flex_df.loc[output_tup,:]\n",
    "# weird neurons\n",
    "print('no NT: {}'.format(pre_onto_ti_ext_flex_df.loc[:,~pre_onto_ti_ext_flex_df.columns.get_level_values('NT').isin(['Ach','GABA','Glu'])].columns.get_level_values('segID').to_list()))\n",
    "# Get rid of the last two pMNs\n",
    "pre_onto_ti_ext_flex_df = pre_onto_ti_ext_flex_df.loc[pre_onto_ti_ext_flex_df.index.get_level_values('NT').isin(['Ach','GABA','Glu']),pre_onto_ti_ext_flex_df.columns.get_level_values('NT').isin(['Ach','GABA','Glu'])]\n",
    "\n",
    "# sort by \n",
    "rows_ntsorted,array = pre_onto_ti_ext_flex_df.index.sortlevel(level='NT',ascending=True,sort_remaining=False)\n",
    "cols_ntsorted,c_array = pre_onto_ti_ext_flex_df.columns.sortlevel(level='NT',ascending=True,sort_remaining=False)\n",
    "local_nt_sorted = pre_onto_ti_ext_flex_df.loc[rows_ntsorted,cols_ntsorted]\n",
    "\n",
    "# order by pool\n",
    "output_tup = ('local',['tibia_extensor','main_tibia_flexor'],All,All,All,All,All)\n",
    "local_nt_pool_sorted = local_nt_sorted.loc[output_tup,output_tup]\n",
    "\n",
    "# mnpoollabel = local_nt_pool_sorted.index.get_level_values('preferred_pool')\n",
    "yticklabels = local_nt_pool_sorted.columns.get_level_values('NT')\n",
    "\n",
    "xpool = local_nt_pool_sorted.index.get_level_values('preferred_pool')\n",
    "pool_dict = {'tibia_extensor':'ext','main_tibia_flexor':'flex'}\n",
    "xpool = [pool_dict[key] for key in xpool]\n",
    "\n",
    "xNT = local_nt_pool_sorted.index.get_level_values('NT').to_list()\n",
    "xpoolnt = [x + \"_\" + y for x,y in zip(xpool,xNT)]\n",
    "\n",
    "conn_heat_map(df=local_nt_pool_sorted, xticks=xpoolnt,yticks=xpoolnt,figsz=[16,16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format a nicer figure with both plots side by side\n",
    "# do it in different colors too, then cut out different versions in illustrator\n",
    "fig, ax = plt.subplots(1, 2, figsize=(32,16),gridspec_kw={'width_ratios': [1, 3.5]})\n",
    "\n",
    "cmap = utils.white_dense()\n",
    "# cmap = sns.color_palette(\"light:seagreen\", as_cmap=True)\n",
    "\n",
    "# def conn_heat_map(df,xticks,yticks,figsz=[16,16],savefig=False,figfilename=None,cmap=cmap):\n",
    "sns.heatmap(np.log10(mn_nt_pool_sorted.T.to_numpy()+1),ax=ax[0], xticklabels=mnpoollabel, yticklabels=xpoolnt, cmap=cmap,square=True,cbar=False,vmax=np.log10(633),vmin=0)\n",
    "plt.xlabel('Onto MNs', fontsize =18)\n",
    "plt.ylabel('From input neurons', fontsize =18)\n",
    "sns.heatmap(np.log10(local_nt_pool_sorted.T.to_numpy()+1),ax=ax[1], xticklabels=xpoolnt, yticklabels=xpoolnt,square=True, cmap=cmap,vmax=np.log10(633),vmin=0)\n",
    "plt.xlabel('Onto local pmns', fontsize =18)\n",
    "\n",
    "cbar = ax[1].collections[0].colorbar\n",
    "cbar.set_label(label = 'log 10 # of synapses', size=24)\n",
    "# plt.yticks(fontsize = 16)\n",
    "# plt.xticks(fontsize = 16)\n",
    "# plt.show()\n",
    "\n",
    "fig.savefig('./figpanels/' + 'local_ti_ext_flex_by_nt' + '.svg',format='svg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mn_nt_pool_sorted.max().max()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.12 ('fanc_analysis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "b315cc870c8bed6572d217175f80b2213d2d88f8d1534b43b9efee2de96efaec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
